#### 主键 外键 索引
- 主键是表中唯一标识一条记录的，不允许有重复的、不能为空
- 外键是用来和其他表建立联系的，表的外键是另一个表的主键，可以有重复的可以为空
- 索引是对数据库中某些关键字段进行存储，类似数据中的目录，里面包含关键数据和数据的位置，索引不能太多，建议一个表不能超过四个



### 索引
#### 索引的定义与优缺点
- 索引是存储引擎 用于快速找到数据记录的一种数据结构，就好比一本教科书的目录部分，通过目录中找到对应文章的页码，便可快速定位到需要的文章。MySQL中也是一样的道理，进行数据查找时，首先查看查询条件是否命中某条索引，符合则通过索引查找相关数据，如果不符合则需要全表扫描,即需要一条一条地查找记录，直到找到与条件符合的记录

- 索引的优点
  （1）提高数据检索的效率，降低数据库的IO成本,这是创建索引最主要的原因。
  （2）通过创建唯一索引，可以保证数据库中每一行数据的唯一性。
  （3）在实现数据的参考完整性方面，可以加速表和表之间的连接。换句话说，对于有依赖关系的子表和父表联合查询时，可以提高查询速度。
  （4）在使用分组和排序子句进行数据查询时，可以显著减少查询中分组和排序的时间，降低了CPU的消耗。

- 索引的 缺点
  （1）创建索引和维护索引要耗费时间，并且随着数据量的增加，所耗费的时间也会增加。
  （2）索引需要占磁盘空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，存储在磁盘上，如果有大量的索引，索引文件就可能比数据文件更快达到最大文件尺寸。
  （3）虽然索引大大提高了查询速度，但却会降低更新表的速度。当对标中的数据进行增加、删除和修改的时候，索引也要动态地维护，这样就降低了数据的维护速度。

#### 聚簇索引 & 非聚簇索引的区别
（1）聚簇索引也就是所谓的主键索引，一般只需要查询一次即可，但是如果是二级索引查询也就是非聚簇索引查询，则需要回表操作，多次查询，在大数据量的情况下，主键索引的效率会很高。
（2） 聚簇索引的叶子节点存储的就是我们的数据记录，非聚簇索引的叶子节点存储的是数据位置（主键位置）。非聚簇索引不会影响数据表的物理存储顺序。
（3）一个表只能有一个聚簇索引，因为只能有一种排序存储的方式，但可以有多个非聚簇索引，也就是多个索引目录提供数据检索。

#### Hash索引与B+树索引的区别（为什么索引结构要设计成树形）
1、Hash索引仅满足（=)（!=）和IN查询。如果进行范围查询，哈希型的索引，时间复杂度会退化为O(n); 而树形的“有序”特性，依然能够保持O(log2N)的高效率。
2、Hash索引不支持联合索引的最左侧原则， 对于联合索引的情况，Hash值是将联合索引合并后一起来计算的，无法对单独的一个键或者几个索引健进行查询。
3、Hash索引还有一个缺陷，数据的存储是没有顺序的，在ORDER BY的情况下，使用Hash索引还需要对数据重新排序。
4、对于等值查询来说，通常Hash索引的效率更高，不过也存在一种情况，就是索引列的重复值如果很多，效率就会降低。这是因为遇到Hash冲突（碰撞）时，需要遍历桶中的行指针来进行比较，找到查询的关键字，非常耗时。
5、InnoDB不支持哈希索引

####  最左前缀原则？
当我们创建一个组合索引的时候，如 (a1,a2,a3)，相当于创建了（a1）、(a1,a2)和(a1,a2,a3)三个索引，这就是 最左前缀原则。  原则上，要根据业务需求，where 子句中使用最频繁的一列放在最左边。

####  B+树和B树的差异
- B+树中有k个关键字（数据页中的记录数）就有k个孩子节点（ 数据页的数量），也就是关键字数 = 孩子数量 ，而B树中，关键字数 + 1 = 孩子数量。

- B+树非叶子节点的关键字 也会同时存在在子节点的关键字中
   这就意味着 B+树的非叶子节点仅用于索引，不保存数据记录，跟记录有关的信息都放在叶子节点中。
   也意味着 B+树中 所有关键字（key）都在叶子节点出现，叶子节点构成一个有序链表，而且叶子节点本身按照关键字的大小从小到大顺序链接。
   而B树中，非叶子节点既保存索引，也保存数据记录。

#### 为什么说B+树比B-树更适合实际应用中操作系统的文件索引和数据库索引？
- 首先，B+树查询效率更稳定。因为B+树每次只有访问到叶子节点才能找到对应的数据，而在B树中，非叶子节点也会存储数据，有时候访问到了非叶子节点就可以找到关键字，

- 其次，B+树的查询效率更高。这是因为通常B+树比B树更矮胖（阶树更大，深度更低），查询所需要的磁盘I/O也会更少。

- 在查找范围上，B+树的效率也比B树高。这是因为所有关键字都出现在B+树的叶子节点中，叶子节点之间会有指针，数据又是递增的，这使得我们范围查找可以通过指针连接查找。而在B树种则需要通过中序遍历才能完成查找范围的查找，效率要低很多。


####MyISAM 与 InnoDB的索引方案对比
- MyISAM的索引方式都是 “非聚簇” 的，InnoDB中一定包含1个聚簇索引
- 在InnoDB存储引擎中，我们只需要根据主键值对 聚簇索引 进行一次查找就能找到对应的记录，而在MyISAM 中却至少需要进行一次 回表（先查找到地址值，再找到对应的记录），意味着MyISAM中建立的索引相当于全部都是 二级索引。
- InnoDB的数据文件本身就是索引文件，而MyISAM索引文件和数据文件是 分离的，索引文件仅保存数据记录的地址。
- InnoDB的非聚簇索引data域存储相应记录 主键的值，而MyISAM索引记录的是 地址
- MyISAM的回表操作是十分 快速 的，因为是拿着地址偏移量直接到文件中取数据的，反观InnoDB是通过获取主键之后再去聚簇索引里找记录，虽然说也不慢，但还是比不上直接用地址去访问。
- InnoDB 要求表 必须有主键（MyISAM可以没有）。如果没有显式指定，则 InnoDB 会自动选择一个可以非空且唯一标识数据记录的列作为主键（如果不存在这种列，则自动创建。

#### B+树的存储能力如何? （为何说一般查找行记录，最多只需1~3次磁盘IO）
InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT(占用4个字节)或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B + 8B) = 1k个键值。也就是说一个深度为3的B+Tree索引可以维护 10 ^ 3 * 10^3 * 10^3 = 10亿条记录。

实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2~4层。MySQL的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。

#### Hash 索引与 B+ 树索引是在建索引的时候手动指定的吗？
针对InnoDB和MyISAM存储引擎，都会默认采用B+树索引，无法使用Hash索引。InnoDB提供的自适应Hash是不需要手动指定的。如果是Memory/Heap和NDB存储引擎，是可以进行选择Hash索引的。

####  B+树是如何进行记录检索的？
首先是从B+树的根开始，逐层检索，直到找到叶子节点，也就是找到对应的数据页为止，将数据页加载到内存中，页目录中的槽采用二分查找的方式先找到一个粗略的记录分组，然后再在分组中通过链表遍历的方式查找记录。

#### 普通索引和唯一索引有什么不同？
唯一索引 指的是对 加有唯一约束 的字段建立的索引，因此该字段不会重复。因此，唯一索引在找到第一个元素后就停止了，普通索引一般只是在找到第一个元素后再多往后进行几次查找即可，其时间消耗并不大(真正消耗时间的是磁盘I/O)。

### 事务
#### 事务四大特性
- 事务：指一组逻辑操作单元，使数据从一种状态变换到另一种状态。
  （1）原子性（Atomicity）
    原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。
  （2） 一致性（Consistency）
    事务必须使数据库从一个一致性状态变换到另外一个一致性状态。例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；
  （3）隔离性（Isolation）
    类似于线程安全问题，当多个用户同时操作表时，需要考虑隔离性事务的隔离性是指一个事务的执行不能被其他事务干扰， 即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
  （4）持久性（Durability）
    持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响

####  数据库的并发下会带来哪些问题？
（0）脏写：对于两个事务 T1, T2，如果事务T1修改了另一个 未提交事务T2修改过的数据，那就意味着发生了脏写.
（1）脏读: 对于两个事务 T1, T2。 T1 读取了已经被 T2 更新但还没有被提交的字段。 T1读取的内容就是临时且无效的。（若T2回滚，数据库中数据其实并未改变，而T1读到的 却是改变的数据）
（2）不可重复读(upgrade): 对于两个事务T1, T2。 T1 读取了一个字段, 然后 T2 更新了该字段（修改并提交）。之后, T1再次读取同一个字段（之前的流未关闭）, 但是值就不同了。
（3）幻读(insert): 对于两个事务T1, T2, T1 从一个表中读取了一个字段, 然后 T2 在该表中插入了一些新的行。之后, 如果 T1 再次读取同一个表（之前的流未关闭）, 但是发现多出几行。我们把新插入的那些记录称之为 幻影记录 。

- 注意：如果T2在该表中 不是插入新记录，而是删除一些记录，T1读取的记录变少了，这种现象不属于幻读，这相当于对每一条记录都发生了不可重复读的现象。幻读只是重点强调了读取到之前读取没有获取到的记录

####  事务隔离级别
- 不同的等级限制了不同的并发范围，实际上隔离等级越高，数据一致性就越好, 但并发性越弱。一般情况下，READ COMMITED就够了，不可重复读和幻读被认为是可以接受的
- 所有的隔离级别都不允许脏写的情况发生！！！
- MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）
（1） READ UNCOMMITED: 所有并发问题未解决
（2） READ COMMITED：只解决了脏读。oracle默认使用该隔离等级
（3） REPEATABLE READ：解决了脏读和不可重复读。MySQL默认使用该隔离等级
（4） SERIALIZABLE：解决了所有并发问题，一般不使用，影响性能。

####  InnoDB 和 MyISM、MEMORY 存储引擎
（1）✔InnoDB 引擎：具备外键支持功能的事务存储引擎
- 支持事务：InnoDB是MySQL的 默认事务型引擎 ，它被设计用来处理大量的短期(short-lived)事务。可以确保事务的完整提交(Commit)和回滚(Rollback)。
- 若除了增加和查询外，还需要更新、删除操作，那么，应优先选择InnoDB存储引擎（效率更高）
- 数据文件结构：① 表名.frm 存储表结构（MySQL8.0时，合并在表名.ibd中）② 表名.ibd 存储数据和索引
- InnoDB是 为处理巨大数据量的最大性能设计 。
- 对比MyISAM的存储引擎， InnoDB写的处理效率差一些 ，并且会占用更多的磁盘空间以保存数据和索引。
- MyISAM只缓存索引，不缓存真实数据；InnoDB不仅缓存索引还要缓存真实数据，对内存要求较高 ，而且内存大小对性能有决定性的影响。

（2）✔MyISAM 引擎：主要的非事务处理存储引擎
- MyISAM提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等，但MyISAM 不支持事务、行级锁、外键 ，有一个毫无疑问的缺陷就是 崩溃后无法安全恢复 。
- MyISAM 是MySQL5.5之前默认的存储引擎
- MyISAM 访问的速度快 ，若对事务完整性没有要求 或者 以SELECT、INSERT为主的应用（以读为主的业务），那么应优先选择MyISAM存储引擎
- 针对数据统计有额外的常数存储。故而 count(*) 的查询效率很高
- 数据文件结构：① 表名.frm 存储表结构② 表名.MYD 存储数据 (MYData)③ 表名.MYI 存储索引 (MYIndex)

| 对比项 | MyISAM | InnoDB |
| ------ | ----------- |--|
| 外键 | 不支持 | 支持 |
| 事务 | 不支持 | 支持 |
| 行表锁  |表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作|行锁，操作时只锁某一行，不对其它行有影响，适合高并发的操作|
| 缓存 |只缓存索引，不缓存真实数据 |不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响|
| 自带系统表使用 |Y |N|
| 关注点 |性能：节省资源、消耗少、简单业务|事务：并发写、事务、更大资源|
| 默认安装   |Y|Y|
| 默认使用   |Y|N|

（3）Memory引擎：置于内存的表
-  Memory采用的逻辑介质是 内存 ， 响应速度很快 ，但是当mysqld守护进程崩溃的时候 数据会丢失 。另外，要求存储的数据是数据长度不变的格式，比如，Blob和Text类型的数据不可用(长度不固定的)。
- Memory表 的查询速度至少比MyISAM表要快一个数量级。缺点是其数据易丢失，生命周期短。基于这个缺陷，选择MEMORY存储引擎时需要特别小心。
-  Memory表 的大小是有限制的



####  InnoDB 行锁实现方式
- 锁分类1：根据数据的操作类型, 分为共享锁/排他锁
- 锁分类2：根据锁粒度，表锁、页锁、行锁
- 锁分类3：根据对待锁的态度，乐观锁与悲观锁
- 锁分类4：根据加锁的方式，隐式锁与显式锁
- 锁分类5：其他锁，全局锁与死锁

- 由于InnoDB 存储引擎只支持行级锁，这里概述一下所有行级锁
（1）记录锁（Record Lock）：行锁（Row Lock）也称为记录锁，顾名思义，就是锁住某一行（某条记录row）。
（2）间隙锁（Gap Lock）： MySQL在 REPEATABLE READ 隔离级别下是可以解决幻读问题的，解决方案有两种，可以使用MVCC方案解决，也可以采用加锁方案解决。 但是在使用加锁方案解决时有个大问题，就是事务在第一次执行读取操作时，那些幻影记录尚不存在，我们无法给这些幻影记录加上记录锁。因此InnoDB提出了一种称之为Gap Locks的锁。
（3）临键锁（Next-Key Locks）：next-key锁的本质就是一个记录锁和一个gap锁的合体，它既能保护该条记录，又能阻止别的事务将新记录插入被保护记录前边的 间隙。
（4）插入意向锁（Insert Intention Locks）：我们说一个事务在插入一条记录时需要判断一下插入位置是不是被别的事务加了gap锁（next-key锁也包含gap锁），如果有的话，插入操作需要等待InnoDB规定事务在等待的时候也需要在内存中生成一个锁结构，表明有事务想在某个间隙中插入新记录，但是现在在等待。直到拥有gap锁的那个事务提交，拥有插入意向锁的事务继续执行。InnoDB就把这种类型的锁命名为Insert Intention Locks。插入意向锁是一种特殊的Gap锁

#### 乐观锁和悲观锁
- 乐观锁：乐观锁认为对同一数据的并发操作不会总发生，属于小概率事件，不用每次都对数据上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，也就是不采用数据库自身的锁机制，而是通过程序来实现。在程序上，我们可以采用版本号机制或者CAS机制实现。
- 悲观锁：悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞 直到它拿到锁（前一个线程释放锁）。 比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁，当其他线程想要访问数据时，都需要阻塞挂起。
- 乐观锁适合读操作多的场景，相对来说写的操作比较少。它的优点在于程序实现，不存在死锁问题，不过适用场景也会相对乐观，因为它阻止不了除了程序以外的数据库操作。
  悲观锁适合写操作多的场景，因为写的操作具有排它性。采用悲观锁的方式，可以在数据库层面阻止其他事务对该数据的操作权限，防止 读 - 写 和 写 - 写 的冲突。

#### 死锁
- 死锁：两个事务都持有对方需要的锁，并且在等待对方释放，并且双方都不会释放自己的锁的情况
-  innodb如何处理死锁
   - （1）方式1：等待，直到超时（innodb_lock_wait_timeout=50s）
    即当两个事务互相等待时，当一个事务等待时间超过设置的阈值时，就将其回滚，另外事务继续进行。这种方法简单有效，在innodb中，参数innodb_lock_wait_timeout 用来设置超时时间。
     - 缺点:对于在线服务来说，这个等待时间往往是无法接受的。
   - （2）方式2：使用死锁检测进行死锁处理
    方式1检测死锁太过被动，innodb还提供了 wait-for graph 算法来主动进行死锁检测，每当加锁请求无法立即满足需要并进入等待时，wait-for graph算法都会被触发。
     算法一旦检测到有死锁，这时候InnoDB存储引擎会选择 回滚undo量最小的事务，让其他事务继续执行(innodb_deadlock_detect=on 表示开启这个逻辑)。
     这是一种较为 主动的死锁检测机制 ，要求数据库保存锁的信息链表 和 事务等待链表 两部分信息。
     - 缺点：每个新的被阻塞的线程，都要判断是不是由于自己的加入导致了死锁，这个操作时间复杂度是O(n)。如果100个并发线程同时更新同一行，意味着要检测100*100= 1万次，1万个线程就会有1千万次检测。

####  MVCC
- 介绍：MVCC是通过数据行的多个版本管理来实现数据库的并发控制。这项技术使得在InnoDB的事务隔离级别下执行一致性读（快照读）操作有了保证。简言之，就是可以 查询到一些正在被另一个事务更新的行，并且可以看到它们被更新之前的值，这样在做查询的时候就不用等待另一个事务释放锁。
- MVCC 的实现依赖于：隐藏字段(trx_id、roll_pointer)、Undo Log、ReadView 。
- MVCC只能在READ COMMTTED和REPEATABLE READ两个隔离级别下工作，假如一个事务已经修改了记录但是尚未提交，我们不能直接读取最新版本的记录，
   - 在隔离级别为 读已提交（Read Committed）时，一个事务中的每一次 SELECT 查询都会重新获取一次ReadView。
   - 当隔离级别为可重复读的时候，就避免了不可重复读，这是因为 一个事务中 只在第一次 SELECT 的时候会获取一次 Read View，而后面所有的 SELECT 都会复用这个 Read View

- MVCC的优势
1. 读写之间阻塞的问题。通过MVCC可以让读写互相不阻塞，即读不阻塞写，写不阻塞读，这样就可以提升事务并发处理能力。
2. 降低了死锁的概率。这是因为MVCC采用了乐观锁的方式，读取数据时并不需要加锁，对于写操作，也只锁定必要的行。
3. 解决快照读的问题。当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。

   
#### ReadView
- readView就是事务在使用MVCC机制进行快照读操作时产生的读视图，ReadView 要解决的主要问题核心问题是 需要判断一下版本链中的哪个版本是当前事务可见的
- Readview中主要包含四个核心内容：
（1）creator_trx_id： 创建这个Read View 的事务 ID。
 (只有在对表中的记录做改动时（增删改时）才会为事务分配事务id，读 事务中的事务id值都默认为0）
（2） trx_ids： 表示在生成ReadView时当前系统中 活跃的读写事务（启动了，但还未提交） 的事务id列表
（3） up_limit_id ：活跃的事务中最小的事务 ID。
（4）low_limit_id：表示生成ReadView时系统中应该分配给下一个事务的id值。low_limit_id 是系统最大的事务id值，这里要注意是系统中的事务id，需要区别于正在活跃的事务ID。

- ReadView的规则：MVCC实现原理
  （1）如果被访问版本的trx_id属性值与ReadView中的creator_trx_id值相同，意味着当前事务 在访问它自己修改过的记录，所以该版本可以被当前事务访问。
  （2）如果被访问版本的trx_id属性值小于ReadView中的up_limit_id值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。
  （3） 如果被访问版本的trx_id属性值大于或等于ReadView中的low_limit_id值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。
  （4）如果被访问版本的trx_id属性值在ReadView的up_limit_id和low_limit_id之间，那就需要判断一下trx_id属性值是不是在 trx_ids 列表中。
   - 如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问。
   - 如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。

### 数据库优化
#### 数据库优化步骤概述
- 首先在s1部分，我们需要观察服务器的状态是否存在周期性波动，如果存在周期性波动，有可能是周期性节点的原因，比如双十一、促销活动等，可以通过增加缓存（A1）这一步骤解决（即通常使用redis那一步骤）
- 如果缓存策略没有解决，就需要开启慢查询，定位执行慢的SQL语句，并使用查询分析工具（EXPLAIN/show profile）进一步分析查询延迟和卡顿的原因
   - 如果是SQL等待时间长，我们可以 调优服务器的参数 ，比如适当增加数据库的缓冲池！！
   - 如果是SQL的执行时间长，我们可以考虑 是索引设计的问题 还是 查询关联的数据表过多，还是因为一些数据表的字段存在设计问题，在这些方面进行调整
- 如果不是上述问题，我们就需要考虑是否是数据库自身的SQL查询性能已经达到了瓶颈，如果达到了性能瓶颈，我们可以考虑 增加服务器（采用读写分离架构） 或者对数据库进行分库分表（垂直分库、垂直分表、水平分表等..）
 - 总结
   - 从效果来说 调整SQL语句和索引优化 > 调整数据表结构 > 调整系统配置（调优服务器参数） > 硬件调整（增加服务器等）
   - 而从成本来说 调整SQL语句和索引优化 < 调整数据表结构 < 调整系统配置（调优服务器参数） < 硬件调整（增加服务器等）
   - 即如果要对数据库进行优化，一定要优先考虑调整SQL语句和索引优化，因为它成本最低，效果最好


#### 慢查询
- MySQL的慢查询日志，用来记录在MySQL中响应时间超过阈值的语句，具体指运行时间超过 long_query_time 的值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10秒以上（不含10秒）的语句，认为是超出了我们的最大忍耐时间值。
- 它的主要作用是，帮助我们发现那些执行时间特别长的SQL查询语句，并且有针对性地进行优化（结合explain进行全面分析），从而提高系统的整体效率



### 日志与备份
#### redo log
- redo log可以简单分为以下两个部分：重做日志的缓冲 和 重做日志文件，
   - 重做日志的缓冲 (redo log buffer)，保存在内存中，是易失的。
   - 重做日志文件 (redo log file)，保存在硬盘中，是持久的。REDO日志文件默认在数据库的根路径下，其中的 ib_logfile8和 ib_logfile1即为REDO日志。
   （1）先将原始数据从磁盘中读入内存中来，修改数据的内存拷贝
   （2）生成一条重做日志并写入redo log buffer，记录的是数据被修改后的值
   （3）刷盘：当事务commit时，将redo log buffer中的内容刷新到 redo log file，对 redo log file采用追加写的方式
   （4）定期将内存中修改的数据刷新到磁盘


- InnoDB引擎的事务采用了WAL技术(Write-Ahead Logging )，这种技术的思想就是 先写日志，再写磁盘，只有日志写入成功，才算事务提交成功，这里的日志就是redo log。

- 当发生宕机且数据未刷到磁盘的时候，可以通过redo log来恢复，保证ACID中的D，这就是redo log的作用✔✔✔

  

#### undo log
- redo log是事务持久性的保证，undo log是事务原子性的保证✔✔✔。在事务中更新数据（DML操作，除了查询）的前置操作其实是要先写入一个undo log。
- Undo日志的作用
1. 回滚数据：undo用于将数据库物理地恢复到执行语句或事务之前的样子。但事实并非如此。undo是逻辑日志，因此只是将数据库逻辑地恢复到原来的样子。所有修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能大不相同。
      - 比如在新增了一条数据后开辟了新的一页进行存储数据，在rollback后，新增的数据会被逻辑删除，但是新开辟的页并不会被删除
2. MVCC（详情看第16章）
  undo的另一个作用是MVCC，即在InnoDB存储引擎中MVCC的实现是通过undo来完成。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。
  
#### redo log与undo log对比
1. redo log：是存储引擎层(innodb)生成的日志，记录的是"物理级别"上的页修改操作，比如页号xx、偏移量yyy写入了'zzz'数据。主要为了保证数据的可靠性;

2. undo log：是存储引擎层(innodb)生成的日志，记录的是 逻辑操作 日志，比如对某一行数据进行了INSERT语句操作，那么undo log就记录一条与之相反的DELETE操作。主要用于事务的回滚(undo log记录的是每个修改操作的 逆操作 ) 和 一致性非锁定读(undo log回滚行记录到某种特定的版本---MVCC，即多版本并发控制)。

   
#### binlog
- binlog：即binary log，二进制日志文件，也叫作变更日志（update log）。它记录了数据库所有执行的DDL 和 DML 等数据库更新事件的语句✔，但是不包含没有修改任何数据的语句（如数据查询语句select、show等）。 它以事件形式 记录并保存在 二进制文件 中。通过这些信息，我们可以再现数据更新操作的全过程。
- binlog主要应用场景：
1. 用于 数据恢复：如果MySQL数据库意外停止，可以通过二进制日志文件来查看用户执行了哪些操作，对数据库服务器文件做了哪些修改，然后根据二进制日志文件中的记录来恢复数据库服务器。
2. 二是用于 数据复制：由于日志的延续性和时效性，master把它的二进制日志传递给slaves来达到 master-slave数据一致的目的。可以说MySQL数据库的 数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性。

####  binlog与redo log对比
- redo log 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎层产生的。
- binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于MySQL Server 层。
- 虽然它们都属于持久化的保证，但是侧重点不同。
1. redo log 让InnoDB存储引擎拥有了崩溃恢复能力。

2. binlog保证了MySQL集群架构的数据一致性

   

#### 主从复制的优点

- MySQL主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。
- 主从复制的优点：
1. 可以提高数据库的吞吐量

2. 读写分离： 我们可以通过主从复制的方式来 同步数据 ，然后通过读写分离提高数据库并发处理能力。具体原因是，其中一个是Master主库，负责写入数据，我们称之为：写库。其它都是Slave从库，负责读取数据，我们称之为：读库。当主库进行更新的时候，会自动将数据复制到从库中，而我们在客户端读取数据的时候，会从从库中进行读取。 面对“读多写少"的需求，采用读写分离的方式，可以实现 更高的并发访问。同时，我们还能对 从服务器 进行负载均衡，让不同的读请求按照策略均匀地分发到不同的从服务器上，让 读取更加顺畅。读取顺畅的另一个原因，就是 减少了锁表的影响，比如我们让主库负责写，当主库出现写锁的时候，不会影响到从库进行SELECT的读取。

3. 数据备份：热备份机制，也就是在主库正常运行的情况下进行的备份，不会影响到服务。
  高可用性：当服务器出现 故障 或 宕机 的情况下，可以 切换 到从服务器上，保证服务的正常运行。

  

#### 主从复制的步骤
- 三个线程：主从复制过程中，会基于3个线程来操作，一个主库线程，两个从库线程。
1. 主库线程1：二进制日志转储线程，主库将二进制日志发送给从库、
2. 从库线程1：从库 I/O 线程，读取到主库的二进制日志转储线程发送的 Binlog 更新部分，并且拷贝到本地的中继日志 （Relay log）。
3. 从库线程2：从库 SQL 线程，读取从库中的中继日志，并且执行日志中的事件，将从库中的数据与主库保持同步。
- 主从复制步骤
1. 步骤1：Master将写操作记录到二进制日志（binlog）。这些记录叫做 二进制日志事件(binary log events);

2. 步骤2：Slave将Master的binary log events拷贝到它的中继日志（relay log）；

3. 步骤3：Slave重做中继日志中的事件，将改变应用到自己的数据库中。 MySQL复制是异步的且串行化的，而且重启后从接入点开始复制。

   

#### 主从复制的延迟问题
- 日志从主库传给从库，从库接收完binlog 到 执行完这个事务。。这个过程所花费的时间即为主从复制的延迟

- 如何降低 主从延迟的时间
  （1）降低多线程大事务并发的概率，优化业务逻辑
  （2）优化SQL，避免慢SQL，减少批量操作，建议写脚本以update-sleep这样的形式完成。
  （3）提高从库机器的配置，减少主库写binlog和从库读binlog的效率差。
  （4）尽量采用短的链路，也就是主库和从库服务器的距离尽量要短，提升端口带宽，减少binlog传输的网络延时。
  （5）实时性要求的业务读强制走主库，从库只做灾备，备份。

  

#### 主从复制的一致性问题
- 半同步复制：原理是在客户端提交COMMIT之后不直接将结果返回给客户端，而是等待至少有一个从库接收到了Binlog，并且写入到中继日志中，再返回给客户端。

- 这样做的好处就是提高了数据的一致性，当然相比于异步复制来说，至少多增加了一个网络连接的延迟，降低了主库写的效率。

- 在MySQL5.7版本中 增加了一个rpl_semi_sync_master_wait_for_slave_count参数，可以对应答的从库数量进行设置，默认为1，也就是说只要有1个从库进行了响应，就可以返回给客户端。

- 如果将这个参数调大,可以提升数据一致性的强度，但也会增加主库等待从库响应的时间。

#### 分库分表
- 随着业务的不断发展，我们的请求量和数据量不断增大，数据库的读写性能开始下降，在优化初期，使用增加索引，读写分离等手段进行优化，随着数据量的不断增加，这些优化手段的效果可能会越来越小，此时就需要使用分库分表来进行优化，对数据进行切分，将单表和单库的数据量控制在一个合理的范围内。当然，分库分表是我们最后的手段，优先考虑其他的方式。
- 分表：在数据库不变的情况下，对数据表进行拆分。 分表后使用连接查询。
   - 1. 水平拆分：在整个表结构不发生变更的情况下！将一张表的数据拆分成多张表，
   - 2. 垂直拆分：把一个有很多字段的表给拆分个成多个表，每个表的结构都不一样，包含的字段不一样。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个个表里去。
   - 当单表数据量过大，读写性能出现瓶颈，可以只分表
- 分库：在数据表数量不变的情况下，对数据库进行拆分。如将两张表拆到两个库中
   - 当数据库读写压力过大，性能出现瓶颈，可以只分库
- 分库分表：即先进行了分表操作，再进行了分库操作
   - 当单表和数据库都出现了性能瓶颈，

- 分库分表的优点
使MySQL从单机到多机，抗多并发的能力更强；
拆分为多个库，数据库服务器的磁盘的使用率大大降低；
单表数据量减小，执行效率显著提升。



