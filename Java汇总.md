- 以单个问题作为一个点，最好是按照学习顺序进行排列，后续方便添加和修改
- 一级标题为最大模块，如javase,javaweb,mysql,mybatis等
- 二级标题为具体模块（为了应付面试，尽量少设二级标题），如集合、IO等
- 三级标题为具体模块分类（为了应付面试，尽量少设三级标题），如list,set,map
- 四级标题为具体问题，如arraylist与linkedarraylist的区别





# 一：javaSE
#### Java语言特点
* **面向对象**(封装，继承，多态) ;
* **平台无关性**，Java是“一次编写，到处运行(Write Once，Run anyWhere)”的语言，很好的可移植性，在引入虚拟机之后，Java语言在不同的平台上运行不需要重新编译。
* **支持多线程。**C++语言没有内置的多线程机制而Java语言却提供了多线程支持;
* **支持网络编程并且很方便。**
* **编译与解释并存;**
- **支持垃圾回收机制**

  

#### 访问（权限）修饰符
Java中，可以使用访问控制符来保护对类、变量、方法和构造方法的访问。Java 支持4种不同的访问权限。public、 protected、default、private。

* private:在同一类内可见，不能修饰类(外部类)
* default (即默认，什么也不写) :在同一包内可见，不使用任何修饰符。
* protected :对不同包的子类可见，不同包其他类就不可见了
* public: 对所有类可见。抽象类只可以public修饰，默认不写也是public修饰
![image-20220630203918058](image\1.png)



#### 基本数据类型

* 整型
  byte: 占用(内存) 1个字节，8位二进制补码表示的整数
  short: 占用2个字节，16位二进制补码表示的整数
  int:占用4个字节，32位二进制补码表示的整数
  long: 占用8个字节，64位二进制补码表示的整数
* 浮点型
  float:占用4个字节，32位单精度浮点数
  double:占用8个字节，64位双精度浮点数
* 字符型
  char: 占用2个字节，16位字符
* 布尔型
  boolean:只有true和false两个取值。通常编译后JVM内部会把boolean类型变量表示为int
  占4个字节。Boolean类型数组一般每个元素表示为一个字节的byte。



#### 值传递机制

 * 值传递。 即将实际参数值的副本（复制品）传入方法内，而参数本身不受影响

 * 形参是基本数据类型：将实参基本数据类型变量的“数据值”传递给形参

 * 形参是引用数据类型：将实参引用数据类型变量的“地址值”传递给形参

    

#### final、finally、finalize的区别

* **final**:被修饰的变量不可变
  ​	       被修饰的方法不允许子类重写，子类可以使用该方法

  ​         被修饰的类不可以被继承，所有方法不可以被重写
  
* **finally：**作为异常处理的一种机制，只能在**try/catch**语句中，并附带一个语句块表示这段语句一定会执行，System.exit(0)可以阻断finally执行

* **finalize：**Object类中的一个基础方法，设计目的保证对象在被垃圾收集前，完成特地资源的回收，但其执行不稳定且有一定性能问题

  


#### 封装 继承 多态

**封装：**不对外暴露类的内部结构，仅提供少量方法供外部使用，提高程序的可维护性

**继承：**可以使用现有类的所有功能，并在无需重新编写原来类的情况下对这些功能进行扩展。新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承，可以快速地创建新的类，可以提高代码的复用性，程序的可维护性，节省大量创建新类的时间，提高我们的开发效率。

**多态：**一个事物的多种形态。以封装和继承为基础，根据运行时对象实际类型使同一行为具有不同表现形式。父类的引用指向子类的对象，调用的方法是子类重写后的方法，多态一般专指重写，既体现了多种类型的传递，又体现了不同类型的特性，即复用了父类的方法，又扩展了自己的逻辑。



#### Static
* static可以修饰成员变量和成员方法
* static修饰成员变量表示该成员变量只在内存中只存储一份，可以被共享访问、修改
* 在不想创建对象的情况下也想调用方法，可以用static

**访问格式**：
类名.静态成员变量
类名.静态成员方法
对象.静态成员变量（不推荐）

 

#### 静态工具类的好处

* 类中都是一些静态方法， 每个方法都是以完成一个共用的功能为目的, 这个类用来给系统开发人员共同使用的。（譬如验证码登录）

* 一次编写，处处可用，提高代码的重用性

* 建议工具类的构造器私有化处理，工具类不需要创建对象

  

#### **静态代码块:** 
 * 可以有输出语句。

 * 可以对类的属性、类的声明进行初始化操作。

 * 静态代码块不可以对非静态的属性初始化。即：不可以调用非静态的属性和方法。

 * 若有多个静态的代码块，那么按照从上到下的顺序依次执行。

 * 静态代码块的执行要先于非静态代码块。

 * ✔静态代码块随着类的加载而加载，且只执行一次。

   

#### 单例模式(拿到的对象都是同一个对象)

* 饿汉单例 

  * ~~~java
    public class SingleInstance
    {
        public static SingleInstance instance = new SingleInstance();
        private SingleInstance(){
            return instance
        }
    }
    ~~~
  
* 懒汉单例

  * ~~~java
    public class SingleInstance
    {
        private static SingleInstance instance;
        private SingleInstance(){}
        public static SingleInstance  getInstance(){
            if(instance == null){
                instance = new SingleInstance();
            }
            return instance;
        }
    }
    ~~~
    



#### 重载和重写

* 重载 指的是同一个类中的多个同名方法构成重载，是行为水平方向的不同实现，对编译器来说，方法名与参数列表组成了唯一键（称为方法签名），JVM通过方法签名决定调用哪种重载方法。

* 重写指子类实现接口或继承父类时，保持方法签名完全相同，实现不同方法体，是行为垂直方向的不同实现。



#### 面向对象和面向过程

* 面向过程最终执行代码大多是可以直接被CPU执行的二进制机械码，面向对象类调用需要实例化，开销较大，且最终执行代码不是二进制机械码，所以面向过程的性能较好。

* 但面向过程代码模块间耦合严重，不易复用、扩展，面向对象代码强调高内聚、低耦合，先抽象模型定义共性行为，再解决实际问题，系统更加灵活，易于维护、复用、扩展。

  

#### 成员变量和局部变量的区别

<img src="image\2.png" alt="image-20220623195309176" style="zoom:80%;" />



#### 继承抽象类/接口的注意事项？

* 一个类如果继承了抽象类，那么这个类必须重写完抽象类的全部抽象方法，否则这个类也必须定义成抽象类

| 语法 维度 | 抽象类                                             |                             接口                             |
| :-------- | -------------------------------------------------- | :----------------------------------------------------------: |
| 成员 变量 | 无特殊要求                                         |                默认 public static final 常量                 |
| 构造 方法 | 有构造方法，不能实例化                             |                   没有构造方法，不能实例化                   |
| 方法      | 抽象类可以没有抽象方法，但有抽象方法一定是抽象类。 | 默认 public abstract，JDK8 支持默认/静态方 法，JDK9 支持私有方法。 |
| 继承      | 单继承                                             |                            多继承                            |



#### 抽象接口与抽象类的异同点

**相同点**
1. 都不能被实例化 
2. 接口的实现类或抽象类的子类都只有实现了接口或抽象类中的方法后才能实例化。

**不同点**

1. 接口只有定义，不能有方法的实现，而抽象类可以有定义与实现，方法可在抽象类中实现。
2. 实现接口的关键字为implements，继承抽象类的关键字为extends。一个类可以实现多个接口，但一个类只能继承一个抽象类。所以，使用接口可以间接地实现多重继承。
3. 接口只能继承接口，抽象类可以实现接口
4. 接口就是一个只有方法和静态常量的类
5. JAVA8后Default修饰后就不需要强制子类再去写新增的抽样方法，JAVA9直接可以Private
6. 描述特征一般用接口，描述概念一般用抽象类



#### String、StringBuffer、StringBuilder的区别

**可变性**

* 简单来说：String 类中使⽤ final 关键字修饰字符数组来保存字符串，所以 **String** **对象是不可变**
* ⽽StringBuilder与StringBuffer都继承⾃**AbstractStringBuilder类**，在AbstractStringBuilder中也是使⽤字符数组保存字符串char[]value，但是没有⽤ final 关键字修饰，所以**这两种对象都是可变的（可变字符串）**。

**线程安全**

* String不可变，所以线程安全
* StringBuilder是非线程安全
* StringBuffer加了Synchronized同步锁，所以线程安全



### List

<img src="image/4.png" alt="image-20220531141905897" style="zoom:67%;" />

- |----collection

  ​       |----list

  ​              |----ArrayList：作为list接口的主要实现类，线程不安全，效率高；底层使用object[] elementData存储

  ​              |----LinkedList：作为list接口的次要实现类，对于频繁的插入、删除操作，使用此类效率比ArrayList高；底层使用双向链表存储

  ​              |----Vector：作为list接口的古老实现类，线程安全，效率低；底层使用object[] elementData存储

  

#### arraylist,linkedlist,vector三者的异同

 *  同：三个类都实现了list接口，存储数据的特点相同：储存有序的，可重复的数据。

 * 异（ArrayList和LinkedList）:

    1. 二者都线程不安全，相对线程安全的Vector，执行效率高。

    2. `ArrayList`是实现了基于动态数组(自动扩展大小)的数据结构，`LinkedList`基于双向链表（JDK1.6 之前为循环链表，JDK1.7 取消了循环。注意双向链表和双向循环链表的区别）的数据结构。对于随机访问get和set，`ArrayList`效率优于`LinkedList`，因为`LinkedList`要移动指针。对于新增和删除操作（add和remove），`LinkedList`比较占优势，因为增加和删除操作ArrayList要整体移动数据。
    3. 内存空间占用：ArrayList 的空间浪费主要体现在在 list 列表的结尾会预留一定的容量空间，而 LinkedList 的空间花费则体现在它的每一个元素都需要消耗比 ArrayList 更多的空间（因为要存放**直接后继**和**直接前驱**以及数据）

 * 异（ArrayList和Vector）：

    1. Vector和ArrayList几乎是完全相同的,唯一的区别在于Vector是同步类(synchronized)，属于强同步类。因此开销就比ArrayList要大，访问要慢。

    2. 正常情况下,大多数的Java程序员使用 ArrayList而不是Vector, 因为同步完全可以由程序员自己来控制。Vector每次扩容请求其大小的2倍空间，而ArrayList是1.5倍。Vector还有一个子类Stack

        

### Set

|----collection接口

​       |----set接口：无序的、不可重复的数据

​                   |----HashSet：作为list接口的主要实现类，线程不安全，可以存储null值（基于 `HashMap` 实现的）

​                               |----LinkedHashSet：作为hashset的子类；遍历其内部数据时，可以按照添加的顺序遍历（基于`LinkedHashMap` 来实现）

​                    |----TreeSet： 可以按照添加对象的指定属性进行排序（基于红黑树）




### Map

<img src="image/5.png"  style="zoom:67%;" />

|----Map:存储双列数据，存储key-value对的数据     ----类似于高中的函数：y=f(x)

​        |----HashMap: 作为Map的主要实现类，线程不安全，效率高; 可以存储null的key和value

​                          |----LinkedHashMap: 保证在遍历map元素时，可以按照添加的顺序实现遍历

​                                                               : 原因，在原有的HashMap底层之上，添加了一对指针（引入了链式结构）

​                                                               ：对于频繁的遍历操作，此类的执行效率高于HashMap

​       |----Hashtable: 作为Map的古老实现类，线程安全，效率低; 不能存储null的key和value

​                          |----Properties：常用来处理配置文件，key和value都是string类型

​       |----TreeMap:可以根据添加的key-value对进行排序，实现排序遍历，通常都是对key进行排序（自然排序，定制排序）

​                                                               :底层使用红黑树



#### jdk7中的底层实现源码流程（饿汉式）

1. HashMap map = new HashMap(); 在实例化以后，底层创建了一个长度为16的一维数组Entry[] table;(看构造器，点this进去)

2.  map.put(key1,value1)(查看Put方法)

​       ① 首先调用key1所在类的hashcode()方法，此hash值经过某种映射，得到在entry数组中的存放位置

​       ② 如果此位置上为空，此时直接添加成功，key1-value1添加成功

​       ③ 如果此位置上数据不为空（意味着此位置上存在一个或多个数据（以链表方式存储）），比较当前key1和已经存在数据的哈希值，如果哈希值不同，添加成功。如果哈希值与某一个数据相同(key2-value2)，继续比较key1所在类的equals()方法，如果equals返回false，添加成功。。 如果equals()返回true,使用value1替换value2

 * 补充：对于原先就有数据的情况，key1-value1和key2-value2以链表的方式存储

 * 扩容：默认扩容为原来容量的2倍，并把原来的数据复制过来

    

#### Jdk8中的底层实现源码流程（懒汉式）

1. HashMap map = new HashMap(); ✔在实例化以后，底层没有创建了一个长度为16的一维数组Node[] table; (改名了而且)
2.  首次调用 map.put(key1,value1)方法时：

​       ① 创建长度为16的一维数组Node[] table;

​       ② jdk8,使用了数组+链表+红黑树

​       ✔当数组的某一个索引位置上有多个元素（以链表方法存储）,元素个数>8 且 当前数组长度>64时，该索引位置上所有数据改用红黑树存储

​       ② 首先调用key1所在类的hashcode()方法，此hash值经过某种映射，得到在entry数组中的存放位置

​       ③ 如果此位置上为空，此时直接添加成功，key1-value1添加成功

​       ④ 如果此位置上数据不为空（意味着此位置上存在一个或多个数据（以链表方式存储）），比较当前key1和已经存在数据的哈希值，

如果哈希值不同，添加成功。如果哈希值与某一个数据相同(key2-value2)，继续比较key1所在类的equals()方法，如果equals返回false，添加成功。。。。如果equals()返回true,使用value1替换value2

 * 补充：对于原先就有数据的情况，key1-value1和key2-value2以链表的方式存储

 * 当形成链表时，七上八下（jdk7中新的元素指向旧元素，jdk8中旧元素指向新元素）

 * 扩容：默认扩容为原来容量的2倍，并把原来的数据复制过来
   
   

#### LinkedHashMap的底层实现原理（了解）
 * 底层使用的结构与hashmap基本相同，因为Linkedhashmap继承于hashmap, 只是重写了newNode方法，

 * 并且 新造了内部类Entry,该Entry对象继承自Node，实现了双向链表，所以LinkedHashMap就可以根据添加的顺序实现遍历

   

#### hashset的底层实现原理
 * 在new HashSet的时候，实际上底层是new了一个HashMap
 * 当我们add元素的时候，实际上是往这个HashMap.put(e, object())
 * ✔✔即我们存入的键值，value处就放一个空的object对象（常量），所有的key都指向它



#### List、Set、Map的区别

* `List`(对付顺序的好帮手)：存储的元素是**有序**的、**可重复**的。

* `Set`(注重独一无二的性质): 存储的元素是**无序**的、**不可重复**的。

* `Map`(用 Key 来搜索的专家): 使用键值对（key-value）存储，类似于数学上的函数 y=f(x)，“x”代表 key，"y"代表 value，Key 是**无序**的、**不可重复**的，value 是**无序**的、**可重复**的，每个键最多映射到一个值。

  

#### HashMap和Hashtable的区别（感觉hashtable基本不会考了）

1.线程是否安全: HashMap 是非线程安全的，HashTable 是线程安全的,因为HashTable 内部的方法基本都经过synchronized修饰。
2.效率:因为线程安全的问题，HashMap 要比HashTable 效率高一点。 另外，HashTable 基本被淘汰，不要在代码中使用它;
3.对Null key和Null value的支持: HashMap 可以存储null 的key和value,但null作为键只能有一个， null 作为值可以有多个; HashTable 不允许有null键和null值，否则会抛出NullPointerException 。
4.初始容量大小和每次扩充容量大小的不同:①创建时如果不指定容量初始值，Hashtable 默认的初始大小为11,之后每次扩充，容量变为原来的2n+1。HashMap 默认的初始化大小为16。之后每次扩充，容量变为原来的2倍。②创建时如果给定了容量初始值，那么Hashtable会直接使用你给定的大小，而HashMap 会将其扩充为2的幂次方大小。
5.**底层数据结构:** JDK1.8 以后的HashMap在解决哈希冲突时有了较大的变化，当链表长度大于阈值(默认为8) (将链表转换成红黑树前会判断，如果当前数组的长度小于64,那么会选择先进行数组扩容，而不是转换为红黑树时，将链表转化为红黑树，以减少搜索时间。Hashtable 没有这样的机制。



#### 为什么转成红黑树

* 链表取元素是从头结点一直遍历到对应的结点，这个过程的复杂度是O(N)， 而红黑树基于二叉树的结构，查找元素的复杂度为O(logN)，所以，当元素个数过多时，用红黑树存储可以提高搜索的效率。

* 可以有效防止用户自己实现了不好的哈希算法时导致链表过长的情况。

  

#### 为什么不一开始转成红黑树

单个TreeNode需要占用的空间大约是普通Node的两倍，所以只有当包含足够多的Nodes时才会转成TreeNodes。



#### 为什么树化标准是8

* 如果hashCode的分布离散良好的话，那么红黑树是很少会被用到的，因为各个值都均匀分布，很少出现链表很长的情况。

* 在理想情况下，链表长度符合泊松分布， 各个长度的命中概率依次递减，当长度为8的时候，概率概率仅为00000006，
  这么小的概率，HashMap的红黑树转换几乎不会发生。
  
* 当然，这是理想的算法，但不妨某些用户使用HashMap过程导致hashCode分布离散很差的场景，这个时候再转换为红黑树
  就是一种很好的退让策略。
  
  

#### 为什么退化为链表的阈值是6
主要是一个过渡，避免链表和红黑树之间频繁的转换。如果阈值是7的话，删除一个元素红黑树就必须退化为链表， 增加一个元
素就必须树化，来回不断的转换结构无疑会降低性能，所以阈值才不设置的那么临界。



#### ConcurrentHashMap和Hashtable的区别

ConcurrentHashMap和Hashtable的区别主要体现在实现线程安全的方式上不同。

* **底层数据结构: **JDK1.7 的ConcurrentHashMap底层采用分段的数组+链表实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样,数组+链表/红黑叉树。Hashtable和JDK1.8之前的HashMap的底层数据结构类似都是采用数组+链表的形式,数组是HashMap的主体,链表则是主要为了解决哈希冲突而存在的;
* **实现线程安全的方式(重要) :**①在JDK1.7的时候，ConcurrentHashMap (分段锁) 对整个桶数组进行了分割分段(Segment),每把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。到了 JDK1.8 的时候已经摒弃了Segment 的概念,而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用synchronized和CAS来操作，**通过对头节点加锁来保证线程安全，使锁的粒度相对于Segment更小了**。JDK1.6 后对synchronized锁做了很多优化)整个看起来就像是优化过且线程安全的HashMap， 虽然在JDK1.8中还能看到Segment的数据结构，但是已经简化了属性，只是为了兼容旧版本;②Hashtable (同步锁) :使用synchronized来保证线程安全,效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态,如使用put添加元素，另一个线程不能使用put添加元素,也不能使用get,竞争会越来越激烈效率越低。
  两者的对比图:
  **HashTable:**

<img src="image\6.png" alt="image-20220531163541193" style="zoom:50%;" />

**JDK1.7 的 ConcurrentHashMap：**

<img src="image\7.png" alt="image-20220531163559293" style="zoom:67%;" />

**JDK1.8 的 ConcurrentHashMap：**

<img src="image\8.png" alt="image-20220531163612886" style="zoom:67%;" />

​		JDK1.8 的 `ConcurrentHashMap` 不在是 **Segment 数组 + HashEntry 数组 + 链表**，而是 **Node 数组 + 链表 / 红黑树**。不过，Node 只能用于链表的情况，红黑树的情况需要使用 **`TreeNode`**。当冲突链表达到一定长度时，链表会转换成红黑树。

总结：JDK1.7给Segment添加ReentrantLock（可重入锁）来实现线程安全

​	   	JDK1.8通过CAS或者synchronized来实现线程安全



#### throw和throws的区别

Java中的异常处理除了包括捕获异常和处理异常之外，还包括声明异常和抛出异常，可以通过throws关键字在方法上声明该方法要抛出的异常，或者在方法内部通过throw拋出异常对象。throws关键字和throw关键字在使用上的几点区别如下:

* throw关键字用在方法内部，只能用于抛出一种异常，用来抛出方法或代码块中的异常，受查异常和非受查异常都可以被抛出。

* throws关键字用在方法声明上，可以抛出多个异常，用来标识该方法可能抛出的异常列表。一个方法用throws标识了可能抛出的异常列表，调用该方法的方法中必须包含可处理异常的代码，否则也要在方法签名中用throws关键字声明相应的异常。

  

#### 处理异常的方式
* throws：用在方法上，可以将方法内部出现的异常抛出去给本方法的调用者处理。
* try...catch：
  * 监视捕获异常，用在方法内部，可以将方法内部出现的异常直接捕获处理。
  * 这种方式还可以，发生异常的方法自己独立完成异常的处理,程序可以继续往下执行。
* 前两者结合


#### 序列化和反序列化
- 用途：对内存中的对象进行持久化或网络传输
- 解释：序列化的原本意图是希望对一个Java对象作一下“变换”，变成字节序列，这样一来方便持久化存储到磁盘，避免程序运行结束后对象就从内存里消失，另外变换成字节序列也更便于网络传输，所以概念上很好理解：怎么把当前JVM进程的对象跨网络传输到另一个JVM进程里面进行恢复。序列化就是把内存里面的对象转化为字节流，以便实现存储或传输。反序列化就是根据从文件或者网络上获取到的对象的字节流，根据字节流里面的保存的对象描述信息和状态重新构建一个新的对象。
- **序列化**： 将数据结构或对象转换成二进制字节流的过程
- **反序列化**：将在序列化过程中所生成的二进制字节流转换成数据结构或者对象的过程


#### 反射的优缺点
通过反射可以获取.class文件得到字节码，从而得到任意一个类的所有属性和方法，还可以调用这些方法和属性。动态获取信息及调用对象方法的功能。反射本质上就是把Java类中的各个成分映射成一个个的Java对象

- **优点** ： 可以让代码更加灵活、为各种框架 开箱即用的功能提供了便利
- **缺点** ：破坏了封装性以及泛型约束。在运行时有了分析操作类的能力，这同样也增加了安全问题。比如可以无视泛型参数的安全检查（泛型参数的安全检查发生在编译时）。另外，反射的性能也要稍差点，不过，对于框架来说实际是影响不大的。


#### 为什么要有无参构造器？
- 反射调用创建实例clazz.newInstance()方法的底层是调用Constructor对象的newInstance()，所以必须保证编写类的时候有个无参构造器。
- 在实例对象的时候，都要不断的向上（父类）回溯到Object（），要想顺利的回溯到Object，就必须给指定调用父类的哪个构造方法，如果没有，就用默认的 super（）。若只有有参构造器，没有无参，可能会发生编译错误。但只有无参，没有有参一定不会出错


#### 深拷贝和浅拷贝
深拷贝和浅拷贝是指在赋值一个对象时，拷贝的深度不同。

**浅拷贝：**在进行深拷贝时，会拷贝所有的属性，并且如果这些属性是对象，也会对这些对象进行深拷贝，直到最底层的基本数据类型为止。这意味着，对于深拷贝后的对象，即使原对象的属性值发生了变化，深拷贝后的对象的属性值也不会受到影响。

**浅拷贝：**相反，浅拷贝只会拷贝对象的第一层属性，如果这些属性是对象，则不会对这些对象进行拷贝，而是直接复制对象的引用。这意味着，对于浅拷贝后的对象，如果原对象的属性值发生了变化，浅拷贝后的对象的属性值也会跟着发生变化。




# 二：数据库
#### 主键 外键 索引
- 主键是表中唯一标识一条记录的，不允许有重复的、不能为空
- 外键是用来和其他表建立联系的，表的外键是另一个表的主键，可以有重复的可以为空
- 索引是对数据库中某些关键字段进行存储，类似数据中的目录，里面包含关键数据和数据的位置，索引不能太多，建议一个表不能超过四个



### 索引
#### 索引的定义与优缺点
- 索引是存储引擎 用于快速找到数据记录的一种数据结构，就好比一本教科书的目录部分，通过目录中找到对应文章的页码，便可快速定位到需要的文章。MySQL中也是一样的道理，进行数据查找时，首先查看查询条件是否命中某条索引，符合则通过索引查找相关数据，如果不符合则需要全表扫描,即需要一条一条地查找记录，直到找到与条件符合的记录

- 索引的优点
  （1）提高数据检索的效率，降低数据库的IO成本,这是创建索引最主要的原因。
  （2）通过创建唯一索引，可以保证数据库中每一行数据的唯一性。
  （3）在实现数据的参考完整性方面，可以加速表和表之间的连接。换句话说，对于有依赖关系的子表和父表联合查询时，可以提高查询速度。
  （4）在使用分组和排序子句进行数据查询时，可以显著减少查询中分组和排序的时间，降低了CPU的消耗。

- 索引的 缺点
  （1）创建索引和维护索引要耗费时间，并且随着数据量的增加，所耗费的时间也会增加。
  （2）索引需要占磁盘空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间，存储在磁盘上，如果有大量的索引，索引文件就可能比数据文件更快达到最大文件尺寸。
  （3）虽然索引大大提高了查询速度，但却会降低更新表的速度。当对标中的数据进行增加、删除和修改的时候，索引也要动态地维护，这样就降低了数据的维护速度。

#### 聚簇索引 & 非聚簇索引的区别
（1）聚簇索引也就是所谓的主键索引，一般只需要查询一次即可，但是如果是二级索引查询也就是非聚簇索引查询，则需要回表操作，多次查询，在大数据量的情况下，主键索引的效率会很高。
（2） 聚簇索引的叶子节点存储的就是我们的数据记录，非聚簇索引的叶子节点存储的是数据位置（主键位置）。非聚簇索引不会影响数据表的物理存储顺序。
（3）一个表只能有一个聚簇索引，因为只能有一种排序存储的方式，但可以有多个非聚簇索引，也就是多个索引目录提供数据检索。

#### Hash索引与B+树索引的区别（为什么索引结构要设计成树形）
1、Hash索引仅满足（=)（!=）和IN查询。如果进行范围查询，哈希型的索引，时间复杂度会退化为O(n); 而树形的“有序”特性，依然能够保持O(log2N)的高效率。
2、Hash索引不支持联合索引的最左侧原则， 对于联合索引的情况，Hash值是将联合索引合并后一起来计算的，无法对单独的一个键或者几个索引健进行查询。
3、Hash索引还有一个缺陷，数据的存储是没有顺序的，在ORDER BY的情况下，使用Hash索引还需要对数据重新排序。
4、对于等值查询来说，通常Hash索引的效率更高，不过也存在一种情况，就是索引列的重复值如果很多，效率就会降低。这是因为遇到Hash冲突（碰撞）时，需要遍历桶中的行指针来进行比较，找到查询的关键字，非常耗时。
5、InnoDB不支持哈希索引

####  最左前缀原则？
当我们创建一个组合索引的时候，如 (a1,a2,a3)，相当于创建了（a1）、(a1,a2)和(a1,a2,a3)三个索引，这就是 最左前缀原则。  原则上，要根据业务需求，where 子句中使用最频繁的一列放在最左边。

####  B+树和B树的差异
- B+树中有k个关键字（数据页中的记录数）就有k个孩子节点（ 数据页的数量），也就是关键字数 = 孩子数量 ，而B树中，关键字数 + 1 = 孩子数量。

- B+树非叶子节点的关键字 也会同时存在在子节点的关键字中
   这就意味着 B+树的非叶子节点仅用于索引，不保存数据记录，跟记录有关的信息都放在叶子节点中。
   也意味着 B+树中 所有关键字（key）都在叶子节点出现，叶子节点构成一个有序链表，而且叶子节点本身按照关键字的大小从小到大顺序链接。
   而B树中，非叶子节点既保存索引，也保存数据记录。

#### 为什么说B+树比B-树更适合实际应用中操作系统的文件索引和数据库索引？
- 首先，B+树查询效率更稳定。因为B+树每次只有访问到叶子节点才能找到对应的数据，而在B树中，非叶子节点也会存储数据，有时候访问到了非叶子节点就可以找到关键字，

- 其次，B+树的查询效率更高。这是因为通常B+树比B树更矮胖（阶树更大，深度更低），查询所需要的磁盘I/O也会更少。

- 在查找范围上，B+树的效率也比B树高。这是因为所有关键字都出现在B+树的叶子节点中，叶子节点之间会有指针，数据又是递增的，这使得我们范围查找可以通过指针连接查找。而在B树种则需要通过中序遍历才能完成查找范围的查找，效率要低很多。


####MyISAM 与 InnoDB的索引方案对比
- MyISAM的索引方式都是 “非聚簇” 的，InnoDB中一定包含1个聚簇索引
- 在InnoDB存储引擎中，我们只需要根据主键值对 聚簇索引 进行一次查找就能找到对应的记录，而在MyISAM 中却至少需要进行一次 回表（先查找到地址值，再找到对应的记录），意味着MyISAM中建立的索引相当于全部都是 二级索引。
- InnoDB的数据文件本身就是索引文件，而MyISAM索引文件和数据文件是 分离的，索引文件仅保存数据记录的地址。
- InnoDB的非聚簇索引data域存储相应记录 主键的值，而MyISAM索引记录的是 地址
- MyISAM的回表操作是十分 快速 的，因为是拿着地址偏移量直接到文件中取数据的，反观InnoDB是通过获取主键之后再去聚簇索引里找记录，虽然说也不慢，但还是比不上直接用地址去访问。
- InnoDB 要求表 必须有主键（MyISAM可以没有）。如果没有显式指定，则 InnoDB 会自动选择一个可以非空且唯一标识数据记录的列作为主键（如果不存在这种列，则自动创建。

#### B+树的存储能力如何? （为何说一般查找行记录，最多只需1~3次磁盘IO）
InnoDB存储引擎中页的大小为16KB，一般表的主键类型为INT(占用4个字节)或BIGINT（占用8个字节），指针类型也一般为4或8个字节，也就是说一个页（B+Tree中的一个节点）中大概存储16KB/(8B + 8B) = 1k个键值。也就是说一个深度为3的B+Tree索引可以维护 10 ^ 3 * 10^3 * 10^3 = 10亿条记录。

实际情况中每个节点可能不能填充满，因此在数据库中，B+Tree的高度一般都在2~4层。MySQL的InnoDB存储引擎在设计时是将根节点常驻内存的，也就是说查找某一键值的行记录时最多只需要1~3次磁盘I/O操作。

#### Hash 索引与 B+ 树索引是在建索引的时候手动指定的吗？
针对InnoDB和MyISAM存储引擎，都会默认采用B+树索引，无法使用Hash索引。InnoDB提供的自适应Hash是不需要手动指定的。如果是Memory/Heap和NDB存储引擎，是可以进行选择Hash索引的。

####  B+树是如何进行记录检索的？
首先是从B+树的根开始，逐层检索，直到找到叶子节点，也就是找到对应的数据页为止，将数据页加载到内存中，页目录中的槽采用二分查找的方式先找到一个粗略的记录分组，然后再在分组中通过链表遍历的方式查找记录。

#### 普通索引和唯一索引有什么不同？
唯一索引 指的是对 加有唯一约束 的字段建立的索引，因此该字段不会重复。因此，唯一索引在找到第一个元素后就停止了，普通索引一般只是在找到第一个元素后再多往后进行几次查找即可，其时间消耗并不大(真正消耗时间的是磁盘I/O)。

### 事务
#### 事务四大特性
- 事务：指一组逻辑操作单元，使数据从一种状态变换到另一种状态。
  （1）原子性（Atomicity）
    原子性是指事务是一个不可分割的工作单位，事务中的操作要么都发生，要么都不发生。
  （2） 一致性（Consistency）
    事务必须使数据库从一个一致性状态变换到另外一个一致性状态。例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的；
  （3）隔离性（Isolation）
    类似于线程安全问题，当多个用户同时操作表时，需要考虑隔离性事务的隔离性是指一个事务的执行不能被其他事务干扰， 即一个事务内部的操作及使用的数据对并发的其他事务是隔离的，并发执行的各个事务之间不能互相干扰。
  （4）持久性（Durability）
    持久性是指一个事务一旦被提交，它对数据库中数据的改变就是永久性的，接下来的其他操作和数据库故障不应该对其有任何影响

####  数据库的并发下会带来哪些问题？
（0）脏写：对于两个事务 T1, T2，如果事务T1修改了另一个 未提交事务T2修改过的数据，那就意味着发生了脏写.
（1）脏读: 对于两个事务 T1, T2。 T1 读取了已经被 T2 更新但还没有被提交的字段。 T1读取的内容就是临时且无效的。（若T2回滚，数据库中数据其实并未改变，而T1读到的 却是改变的数据）
（2）不可重复读(upgrade): 对于两个事务T1, T2。 T1 读取了一个字段, 然后 T2 更新了该字段（修改并提交）。之后, T1再次读取同一个字段（之前的流未关闭）, 但是值就不同了。
（3）幻读(insert): 对于两个事务T1, T2, T1 从一个表中读取了一个字段, 然后 T2 在该表中插入了一些新的行。之后, 如果 T1 再次读取同一个表（之前的流未关闭）, 但是发现多出几行。我们把新插入的那些记录称之为 幻影记录 。

- 注意：如果T2在该表中 不是插入新记录，而是删除一些记录，T1读取的记录变少了，这种现象不属于幻读，这相当于对每一条记录都发生了不可重复读的现象。幻读只是重点强调了读取到之前读取没有获取到的记录

####  事务隔离级别
- 不同的等级限制了不同的并发范围，实际上隔离等级越高，数据一致性就越好, 但并发性越弱。一般情况下，READ COMMITED就够了，不可重复读和幻读被认为是可以接受的
- 所有的隔离级别都不允许脏写的情况发生！！！
- MySQL InnoDB 存储引擎的默认支持的隔离级别是 REPEATABLE-READ（可重读）
（1） READ UNCOMMITED: 所有并发问题未解决
（2） READ COMMITED：只解决了脏读。oracle默认使用该隔离等级
（3） REPEATABLE READ：解决了脏读和不可重复读。MySQL默认使用该隔离等级
（4） SERIALIZABLE：解决了所有并发问题，一般不使用，影响性能。

####  InnoDB 和 MyISM、MEMORY 存储引擎
（1）✔InnoDB 引擎：具备外键支持功能的事务存储引擎
- 支持事务：InnoDB是MySQL的 默认事务型引擎 ，它被设计用来处理大量的短期(short-lived)事务。可以确保事务的完整提交(Commit)和回滚(Rollback)。
- 若除了增加和查询外，还需要更新、删除操作，那么，应优先选择InnoDB存储引擎（效率更高）
- 数据文件结构：① 表名.frm 存储表结构（MySQL8.0时，合并在表名.ibd中）② 表名.ibd 存储数据和索引
- InnoDB是 为处理巨大数据量的最大性能设计 。
- 对比MyISAM的存储引擎， InnoDB写的处理效率差一些 ，并且会占用更多的磁盘空间以保存数据和索引。
- MyISAM只缓存索引，不缓存真实数据；InnoDB不仅缓存索引还要缓存真实数据，对内存要求较高 ，而且内存大小对性能有决定性的影响。

（2）✔MyISAM 引擎：主要的非事务处理存储引擎
- MyISAM提供了大量的特性，包括全文索引、压缩、空间函数(GIS)等，但MyISAM 不支持事务、行级锁、外键 ，有一个毫无疑问的缺陷就是 崩溃后无法安全恢复 。
- MyISAM 是MySQL5.5之前默认的存储引擎
- MyISAM 访问的速度快 ，若对事务完整性没有要求 或者 以SELECT、INSERT为主的应用（以读为主的业务），那么应优先选择MyISAM存储引擎
- 针对数据统计有额外的常数存储。故而 count(*) 的查询效率很高
- 数据文件结构：① 表名.frm 存储表结构② 表名.MYD 存储数据 (MYData)③ 表名.MYI 存储索引 (MYIndex)

| 对比项 | MyISAM | InnoDB |
| ------ | ----------- |--|
| 外键 | 不支持 | 支持 |
| 事务 | 不支持 | 支持 |
| 行表锁  |表锁，即使操作一条记录也会锁住整个表，不适合高并发的操作|行锁，操作时只锁某一行，不对其它行有影响，适合高并发的操作|
| 缓存 |只缓存索引，不缓存真实数据 |不仅缓存索引还要缓存真实数据，对内存要求较高，而且内存大小对性能有决定性的影响|
| 自带系统表使用 |Y |N|
| 关注点 |性能：节省资源、消耗少、简单业务|事务：并发写、事务、更大资源|
| 默认安装   |Y|Y|
| 默认使用   |Y|N|

（3）Memory引擎：置于内存的表
-  Memory采用的逻辑介质是 内存 ， 响应速度很快 ，但是当mysqld守护进程崩溃的时候 数据会丢失 。另外，要求存储的数据是数据长度不变的格式，比如，Blob和Text类型的数据不可用(长度不固定的)。
- Memory表 的查询速度至少比MyISAM表要快一个数量级。缺点是其数据易丢失，生命周期短。基于这个缺陷，选择MEMORY存储引擎时需要特别小心。
-  Memory表 的大小是有限制的



####  InnoDB 行锁实现方式
- 锁分类1：根据数据的操作类型, 分为共享锁/排他锁
- 锁分类2：根据锁粒度，表锁、页锁、行锁
- 锁分类3：根据对待锁的态度，乐观锁与悲观锁
- 锁分类4：根据加锁的方式，隐式锁与显式锁
- 锁分类5：其他锁，全局锁与死锁

- 由于InnoDB 存储引擎只支持行级锁，这里概述一下所有行级锁
（1）记录锁（Record Lock）：行锁（Row Lock）也称为记录锁，顾名思义，就是锁住某一行（某条记录row）。
（2）间隙锁（Gap Lock）： MySQL在 REPEATABLE READ 隔离级别下是可以解决幻读问题的，解决方案有两种，可以使用MVCC方案解决，也可以采用加锁方案解决。 但是在使用加锁方案解决时有个大问题，就是事务在第一次执行读取操作时，那些幻影记录尚不存在，我们无法给这些幻影记录加上记录锁。因此InnoDB提出了一种称之为Gap Locks的锁。
（3）临键锁（Next-Key Locks）：next-key锁的本质就是一个记录锁和一个gap锁的合体，它既能保护该条记录，又能阻止别的事务将新记录插入被保护记录前边的 间隙。
（4）插入意向锁（Insert Intention Locks）：我们说一个事务在插入一条记录时需要判断一下插入位置是不是被别的事务加了gap锁（next-key锁也包含gap锁），如果有的话，插入操作需要等待InnoDB规定事务在等待的时候也需要在内存中生成一个锁结构，表明有事务想在某个间隙中插入新记录，但是现在在等待。直到拥有gap锁的那个事务提交，拥有插入意向锁的事务继续执行。InnoDB就把这种类型的锁命名为Insert Intention Locks。插入意向锁是一种特殊的Gap锁

#### 乐观锁和悲观锁
- 乐观锁：乐观锁认为对同一数据的并发操作不会总发生，属于小概率事件，不用每次都对数据上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，也就是不采用数据库自身的锁机制，而是通过程序来实现。在程序上，我们可以采用版本号机制或者CAS机制实现。
- 悲观锁：悲观锁总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞 直到它拿到锁（前一个线程释放锁）。 比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁，当其他线程想要访问数据时，都需要阻塞挂起。
- 乐观锁适合读操作多的场景，相对来说写的操作比较少。它的优点在于程序实现，不存在死锁问题，不过适用场景也会相对乐观，因为它阻止不了除了程序以外的数据库操作。
  悲观锁适合写操作多的场景，因为写的操作具有排它性。采用悲观锁的方式，可以在数据库层面阻止其他事务对该数据的操作权限，防止 读 - 写 和 写 - 写 的冲突。

#### 死锁
- 死锁：两个事务都持有对方需要的锁，并且在等待对方释放，并且双方都不会释放自己的锁的情况
-  innodb如何处理死锁
   - （1）方式1：等待，直到超时（innodb_lock_wait_timeout=50s）
    即当两个事务互相等待时，当一个事务等待时间超过设置的阈值时，就将其回滚，另外事务继续进行。这种方法简单有效，在innodb中，参数innodb_lock_wait_timeout 用来设置超时时间。
     - 缺点:对于在线服务来说，这个等待时间往往是无法接受的。
   - （2）方式2：使用死锁检测进行死锁处理
    方式1检测死锁太过被动，innodb还提供了 wait-for graph 算法来主动进行死锁检测，每当加锁请求无法立即满足需要并进入等待时，wait-for graph算法都会被触发。
     算法一旦检测到有死锁，这时候InnoDB存储引擎会选择 回滚undo量最小的事务，让其他事务继续执行(innodb_deadlock_detect=on 表示开启这个逻辑)。
     这是一种较为 主动的死锁检测机制 ，要求数据库保存锁的信息链表 和 事务等待链表 两部分信息。
     - 缺点：每个新的被阻塞的线程，都要判断是不是由于自己的加入导致了死锁，这个操作时间复杂度是O(n)。如果100个并发线程同时更新同一行，意味着要检测100*100= 1万次，1万个线程就会有1千万次检测。

####  MVCC
- 介绍：MVCC是通过数据行的多个版本管理来实现数据库的并发控制。这项技术使得在InnoDB的事务隔离级别下执行一致性读（快照读）操作有了保证。简言之，就是可以 查询到一些正在被另一个事务更新的行，并且可以看到它们被更新之前的值，这样在做查询的时候就不用等待另一个事务释放锁。
- MVCC 的实现依赖于：隐藏字段(trx_id、roll_pointer)、Undo Log、ReadView 。
- MVCC只能在READ COMMTTED和REPEATABLE READ两个隔离级别下工作，假如一个事务已经修改了记录但是尚未提交，我们不能直接读取最新版本的记录，
   - 在隔离级别为 读已提交（Read Committed）时，一个事务中的每一次 SELECT 查询都会重新获取一次ReadView。
   - 当隔离级别为可重复读的时候，就避免了不可重复读，这是因为 一个事务中 只在第一次 SELECT 的时候会获取一次 Read View，而后面所有的 SELECT 都会复用这个 Read View

- MVCC的优势
1. 读写之间阻塞的问题。通过MVCC可以让读写互相不阻塞，即读不阻塞写，写不阻塞读，这样就可以提升事务并发处理能力。
2. 降低了死锁的概率。这是因为MVCC采用了乐观锁的方式，读取数据时并不需要加锁，对于写操作，也只锁定必要的行。
3. 解决快照读的问题。当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。

   
#### ReadView
- readView就是事务在使用MVCC机制进行快照读操作时产生的读视图，ReadView 要解决的主要问题核心问题是 需要判断一下版本链中的哪个版本是当前事务可见的
- Readview中主要包含四个核心内容：
（1）creator_trx_id： 创建这个Read View 的事务 ID。
 (只有在对表中的记录做改动时（增删改时）才会为事务分配事务id，读 事务中的事务id值都默认为0）
（2） trx_ids： 表示在生成ReadView时当前系统中 活跃的读写事务（启动了，但还未提交） 的事务id列表
（3） up_limit_id ：活跃的事务中最小的事务 ID。
（4）low_limit_id：表示生成ReadView时系统中应该分配给下一个事务的id值。low_limit_id 是系统最大的事务id值，这里要注意是系统中的事务id，需要区别于正在活跃的事务ID。

- ReadView的规则：MVCC实现原理
  （1）如果被访问版本的trx_id属性值与ReadView中的creator_trx_id值相同，意味着当前事务 在访问它自己修改过的记录，所以该版本可以被当前事务访问。
  （2）如果被访问版本的trx_id属性值小于ReadView中的up_limit_id值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。
  （3） 如果被访问版本的trx_id属性值大于或等于ReadView中的low_limit_id值，表明生成该版本的事务在当前事务生成ReadView后才开启，所以该版本不可以被当前事务访问。
  （4）如果被访问版本的trx_id属性值在ReadView的up_limit_id和low_limit_id之间，那就需要判断一下trx_id属性值是不是在 trx_ids 列表中。
   - 如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问。
   - 如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。

### 数据库优化
#### 数据库优化步骤概述
- 首先在s1部分，我们需要观察服务器的状态是否存在周期性波动，如果存在周期性波动，有可能是周期性节点的原因，比如双十一、促销活动等，可以通过增加缓存（A1）这一步骤解决（即通常使用redis那一步骤）
- 如果缓存策略没有解决，就需要开启慢查询，定位执行慢的SQL语句，并使用查询分析工具（EXPLAIN/show profile）进一步分析查询延迟和卡顿的原因
   - 如果是SQL等待时间长，我们可以 调优服务器的参数 ，比如适当增加数据库的缓冲池！！
   - 如果是SQL的执行时间长，我们可以考虑 是索引设计的问题 还是 查询关联的数据表过多，还是因为一些数据表的字段存在设计问题，在这些方面进行调整
- 如果不是上述问题，我们就需要考虑是否是数据库自身的SQL查询性能已经达到了瓶颈，如果达到了性能瓶颈，我们可以考虑 增加服务器（采用读写分离架构） 或者对数据库进行分库分表（垂直分库、垂直分表、水平分表等..）
 - 总结
   - 从效果来说 调整SQL语句和索引优化 > 调整数据表结构 > 调整系统配置（调优服务器参数） > 硬件调整（增加服务器等）
   - 而从成本来说 调整SQL语句和索引优化 < 调整数据表结构 < 调整系统配置（调优服务器参数） < 硬件调整（增加服务器等）
   - 即如果要对数据库进行优化，一定要优先考虑调整SQL语句和索引优化，因为它成本最低，效果最好


#### 慢查询
- MySQL的慢查询日志，用来记录在MySQL中响应时间超过阈值的语句，具体指运行时间超过 long_query_time 的值的SQL，则会被记录到慢查询日志中。long_query_time的默认值为10，意思是运行10秒以上（不含10秒）的语句，认为是超出了我们的最大忍耐时间值。
- 它的主要作用是，帮助我们发现那些执行时间特别长的SQL查询语句，并且有针对性地进行优化（结合explain进行全面分析），从而提高系统的整体效率



### 日志与备份
#### redo log
- redo log可以简单分为以下两个部分：重做日志的缓冲 和 重做日志文件，
   - 重做日志的缓冲 (redo log buffer)，保存在内存中，是易失的。
   - 重做日志文件 (redo log file)，保存在硬盘中，是持久的。REDO日志文件默认在数据库的根路径下，其中的 ib_logfile8和 ib_logfile1即为REDO日志。
   （1）先将原始数据从磁盘中读入内存中来，修改数据的内存拷贝
   （2）生成一条重做日志并写入redo log buffer，记录的是数据被修改后的值
   （3）刷盘：当事务commit时，将redo log buffer中的内容刷新到 redo log file，对 redo log file采用追加写的方式
   （4）定期将内存中修改的数据刷新到磁盘


- InnoDB引擎的事务采用了WAL技术(Write-Ahead Logging )，这种技术的思想就是 先写日志，再写磁盘，只有日志写入成功，才算事务提交成功，这里的日志就是redo log。

- 当发生宕机且数据未刷到磁盘的时候，可以通过redo log来恢复，保证ACID中的D，这就是redo log的作用✔✔✔

  

#### undo log
- redo log是事务持久性的保证，undo log是事务原子性的保证✔✔✔。在事务中更新数据（DML操作，除了查询）的前置操作其实是要先写入一个undo log。
- Undo日志的作用
1. 回滚数据：undo用于将数据库物理地恢复到执行语句或事务之前的样子。但事实并非如此。undo是逻辑日志，因此只是将数据库逻辑地恢复到原来的样子。所有修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能大不相同。
      - 比如在新增了一条数据后开辟了新的一页进行存储数据，在rollback后，新增的数据会被逻辑删除，但是新开辟的页并不会被删除
2. MVCC（详情看第16章）
  undo的另一个作用是MVCC，即在InnoDB存储引擎中MVCC的实现是通过undo来完成。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。
  
#### redo log与undo log对比
1. redo log：是存储引擎层(innodb)生成的日志，记录的是"物理级别"上的页修改操作，比如页号xx、偏移量yyy写入了'zzz'数据。主要为了保证数据的可靠性;

2. undo log：是存储引擎层(innodb)生成的日志，记录的是 逻辑操作 日志，比如对某一行数据进行了INSERT语句操作，那么undo log就记录一条与之相反的DELETE操作。主要用于事务的回滚(undo log记录的是每个修改操作的 逆操作 ) 和 一致性非锁定读(undo log回滚行记录到某种特定的版本---MVCC，即多版本并发控制)。

   
#### binlog
- binlog：即binary log，二进制日志文件，也叫作变更日志（update log）。它记录了数据库所有执行的DDL 和 DML 等数据库更新事件的语句✔，但是不包含没有修改任何数据的语句（如数据查询语句select、show等）。 它以事件形式 记录并保存在 二进制文件 中。通过这些信息，我们可以再现数据更新操作的全过程。
- binlog主要应用场景：
1. 用于 数据恢复：如果MySQL数据库意外停止，可以通过二进制日志文件来查看用户执行了哪些操作，对数据库服务器文件做了哪些修改，然后根据二进制日志文件中的记录来恢复数据库服务器。
2. 二是用于 数据复制：由于日志的延续性和时效性，master把它的二进制日志传递给slaves来达到 master-slave数据一致的目的。可以说MySQL数据库的 数据备份、主备、主主、主从都离不开binlog，需要依靠binlog来同步数据，保证数据一致性。

####  binlog与redo log对比
- redo log 它是物理日志，记录内容是“在某个数据页上做了什么修改”，属于 InnoDB 存储引擎层产生的。
- binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于MySQL Server 层。
- 虽然它们都属于持久化的保证，但是侧重点不同。
1. redo log 让InnoDB存储引擎拥有了崩溃恢复能力。

2. binlog保证了MySQL集群架构的数据一致性

   

#### 主从复制的优点

- MySQL主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。
- 主从复制的优点：
1. 可以提高数据库的吞吐量

2. 读写分离： 我们可以通过主从复制的方式来 同步数据 ，然后通过读写分离提高数据库并发处理能力。具体原因是，其中一个是Master主库，负责写入数据，我们称之为：写库。其它都是Slave从库，负责读取数据，我们称之为：读库。当主库进行更新的时候，会自动将数据复制到从库中，而我们在客户端读取数据的时候，会从从库中进行读取。 面对“读多写少"的需求，采用读写分离的方式，可以实现 更高的并发访问。同时，我们还能对 从服务器 进行负载均衡，让不同的读请求按照策略均匀地分发到不同的从服务器上，让 读取更加顺畅。读取顺畅的另一个原因，就是 减少了锁表的影响，比如我们让主库负责写，当主库出现写锁的时候，不会影响到从库进行SELECT的读取。

3. 数据备份：热备份机制，也就是在主库正常运行的情况下进行的备份，不会影响到服务。
  高可用性：当服务器出现 故障 或 宕机 的情况下，可以 切换 到从服务器上，保证服务的正常运行。

  

#### 主从复制的步骤
- 三个线程：主从复制过程中，会基于3个线程来操作，一个主库线程，两个从库线程。
1. 主库线程1：二进制日志转储线程，主库将二进制日志发送给从库、
2. 从库线程1：从库 I/O 线程，读取到主库的二进制日志转储线程发送的 Binlog 更新部分，并且拷贝到本地的中继日志 （Relay log）。
3. 从库线程2：从库 SQL 线程，读取从库中的中继日志，并且执行日志中的事件，将从库中的数据与主库保持同步。
- 主从复制步骤
1. 步骤1：Master将写操作记录到二进制日志（binlog）。这些记录叫做 二进制日志事件(binary log events);

2. 步骤2：Slave将Master的binary log events拷贝到它的中继日志（relay log）；

3. 步骤3：Slave重做中继日志中的事件，将改变应用到自己的数据库中。 MySQL复制是异步的且串行化的，而且重启后从接入点开始复制。

   

#### 主从复制的延迟问题
- 日志从主库传给从库，从库接收完binlog 到 执行完这个事务。。这个过程所花费的时间即为主从复制的延迟

- 如何降低 主从延迟的时间
  （1）降低多线程大事务并发的概率，优化业务逻辑
  （2）优化SQL，避免慢SQL，减少批量操作，建议写脚本以update-sleep这样的形式完成。
  （3）提高从库机器的配置，减少主库写binlog和从库读binlog的效率差。
  （4）尽量采用短的链路，也就是主库和从库服务器的距离尽量要短，提升端口带宽，减少binlog传输的网络延时。
  （5）实时性要求的业务读强制走主库，从库只做灾备，备份。

  

#### 主从复制的一致性问题
- 半同步复制：原理是在客户端提交COMMIT之后不直接将结果返回给客户端，而是等待至少有一个从库接收到了Binlog，并且写入到中继日志中，再返回给客户端。

- 这样做的好处就是提高了数据的一致性，当然相比于异步复制来说，至少多增加了一个网络连接的延迟，降低了主库写的效率。

- 在MySQL5.7版本中 增加了一个rpl_semi_sync_master_wait_for_slave_count参数，可以对应答的从库数量进行设置，默认为1，也就是说只要有1个从库进行了响应，就可以返回给客户端。

- 如果将这个参数调大,可以提升数据一致性的强度，但也会增加主库等待从库响应的时间。

#### 分库分表
- 随着业务的不断发展，我们的请求量和数据量不断增大，数据库的读写性能开始下降，在优化初期，使用增加索引，读写分离等手段进行优化，随着数据量的不断增加，这些优化手段的效果可能会越来越小，此时就需要使用分库分表来进行优化，对数据进行切分，将单表和单库的数据量控制在一个合理的范围内。当然，分库分表是我们最后的手段，优先考虑其他的方式。
- 分表：在数据库不变的情况下，对数据表进行拆分。 分表后使用连接查询。
   - 1. 水平拆分：在整个表结构不发生变更的情况下！将一张表的数据拆分成多张表，
   - 2. 垂直拆分：把一个有很多字段的表给拆分个成多个表，每个表的结构都不一样，包含的字段不一样。一般来说，会将较少的访问频率很高的字段放到一个表里去，然后将较多的访问频率很低的字段放到另外一个个表里去。
   - 当单表数据量过大，读写性能出现瓶颈，可以只分表
- 分库：在数据表数量不变的情况下，对数据库进行拆分。如将两张表拆到两个库中
   - 当数据库读写压力过大，性能出现瓶颈，可以只分库
- 分库分表：即先进行了分表操作，再进行了分库操作
   - 当单表和数据库都出现了性能瓶颈，

- 分库分表的优点
使MySQL从单机到多机，抗多并发的能力更强；
拆分为多个库，数据库服务器的磁盘的使用率大大降低；
单表数据量减小，执行效率显著提升。







# 三：计算机网络
### IO模型
- Socket套接字：客户端发送数据 以及 服务端接收数据都需要一个口子，这两个口子就是socket。使用socket进行网络通信如下图所示。
- FD文件描述符：是一个非负整数，linux中有着一切皆文件的设计理念，在linux中的一切资源都可以通过文件的方式进行访问和管理。而FD就类似于文件的索引（指向某个具体文件），linux的内核（kernel）就是利用FD来访问和管理资源
  <img src="image\9.png" style="zoom:40">
- **举例说明各种IO模型，实际也是进化的过程**(同步阻塞==>同步非阻塞==>select/poll==>epoll):
  你是一个老师，让学生做作业，学生做完作业后收作业。

#### **（1）同步阻塞IO（BIO模型）:**

解释1：逐个收作业，先收A,再收B,接着是C、D,如果有一个学生还未做完，则你会等到他写完，然后才继续收下一个。

解释2✔：如图，在服务端完成socket初始化后，调用accept方法等待客户端建立连接（阻塞等待），客户端服务端三次握手建立连接后，继续等待客户端发送数据（阻塞等待），直到处理完客户端1的请求后才去处理客户端2
<img src="image/11.png">
<img src="image/12.png">

缺点：

单线程：若某个socket阻塞，会影响到其他socket的处理
多线程：即若为每个连接都分配一个线程来进行管理，则若出现下图中的情况，socket在不同的时间内就绪。实际上只需要单线程就可以处理，这种情况下会造成资源的浪费。并且，线程的调度、上下文切换乃至它们占用的内存，可能都会成为瓶颈。

<img src="image/10.png" style="zoom:67%;"> 

#### **（2）同步非阻塞IO:**

解释1：逐个收作业，先收A,再收B,接着是C、D,如果有一个学生还未做完,则你会跳过该学生，继续去收下一个。

解释2✔： 服务端不断的检查是否客户端有发起连接（接收到的fd是否为非负整数），如果客户端没有发起连接，返回的fd就是一个负数，直到轮巡到有正常数据到来的fd
<img src="image/13.png" style="zoom:67%;">

解释3：从操作系统的底层来看，目前的linux操作系统底层分为用户空间（用户态）和内核空间（内核态），在用户空间下执行一些安全的用户指令，在内核空间中执行一些特权指令。socket的操作是需要在内核空间中完成的，但是内核将socket调用的能力的封装成了系统调用函数（read,write）供用户空间使用。在用户空间调用系统调用函数，由内核空间执行，并将结果返回用户空间。。。。。`read函数`：数据从网卡拷贝到内核空间，再从内核空间拷贝到用户空间。`write函数`：数据从用户空间拷贝到内核空间，再从内核空间拷贝到网卡上，

以建立四个socket连接为例，当用户调用read/write函数时，如果没有就绪的数据，非阻塞IO会马上返回非法fd，然后主线程继续查看下一个连接，而不是像阻塞IO一样阻塞住。
<img src="image/14.png" style="zoom:67%;">

优点：单个socket不会影响到其他socket
缺点：需要不断的遍历进行系统调用(read)来检查数据是否到来，这个系统调用涉及到用户态和内核态的转换，当socket比较多的时候，这会是一笔很大的开销。


#### （3）IO多路复用模型select:（NIO模型）

- IO多路复用模型主要能解决同步非阻塞IO下系统调用频繁的问题

- 解释1：学生写完作业会举手，但是你不知道是谁举手，需要一个个的去询问。

- 解释2✔：在用户空间调用select函数后，会将四个fd拷贝一份到内核空间，由内核空间进行遍历，检查这四个fd对应的socket是否有数据到来，遍历后返回 就绪的fd的数量（复用了fd_set，fd_set入参时表示监听的fd，回参时表示就绪的fd）。返回后用户空间知道有数据就绪，但并不知道是哪一个fd上的socket就绪，所以用户空间上也需要进行遍历
  <img src="image/15.png" style="zoom:%;">
  <img src="image/16.png" style="zoom:%;">

- 优点：将socket是否就绪检查逻辑下沉到操作系统层面，避免大量系统调用。由于不需要每个 FD 都进行一次系统调用，解决了频繁的用户态内核态切换问题

- 缺点：
  单进程（每个进程）监听的 FD 存在限制（由于底层使用数组存储），默认1024
  每次调用需要将 FD 从用户态拷贝到内核态
  不知道具体是哪个文件描述符就绪，需要遍历全部文件描述符
  入参的 3个 fd_set 集合每次调用都需要重置

  

#### **（4）IO多路复用模型poll:**

  <img src="image/17.png" style="zoom:%;">

- 解释：Poll 跟 select 基本一样，主要优化了监听1024的限制。主要就是通过数据结构的优化，底层使用链表存储数据，打破了1024的限制，此外，利用两个不同的参数来存储监听事件和就绪事件，所以无需每次都重置fd_set。

- 优点：将socket是否就绪检查逻辑下沉到操作系统层面，避免大量系统调用。由于不需要每个 FD 都进行一次系统调用，解决了频繁的用户态内核态切换问题

- 缺点：
  每次调用需要将 FD 从用户态拷贝到内核态
  不知道具体是哪个文件描述符就绪，需要遍历全部文件描述符




#### **（5）IO多路复用模型epoll:**

- 问题：select/poll中，每次调用还需要将fd全部复制一份到内核空间中，如果fd比较大，这也是一个比较大的开销，此外，在返回就绪事件时，select/poll是无法知道具体是哪个fd就绪的，这就需要再次进行遍历，这也是一个比较大的开销
- 解释1：学生写完了作业会举手，你知道是谁举手，你直接去收作业。
- 解释2✔：epoll实际上是将文件描述符直接维护在内核态中（使用红黑树），由此解决了select/poll中，每次调用还需要将fd全部复制一份到内核空间中。此外，通过就绪列表，可以知道哪些文件描述符是就绪的，用户空间无需再次进行遍历。

- 缺点：
  跨平台性不够好，只支持 linux，macOS 等操作系统不支持
  相较于 epoll，select 更轻量可移植性更强
  在监听连接数和事件较少的场景下，select 可能更优

