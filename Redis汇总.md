#### redis简介
- Remote Dictionary Server(远程字典服务)是完全开源的，遵守BSD协议，是一个高性能的Key-Value 内存 数据库（数据是存在内存中的）
- 提供了丰富的数据结构，例如String、Hash、List、Set、SortedSet等等。✔同时Redis支持事务、持久化、LUA脚本、发布/订阅、缓存淘汰、流技术等多种功能特性提供了主从模式、Redis Sentinel和Redis Cluster集群架构方案
- redis 属于非关系型数据库（NOSQL），即内部数据使用key-value方式存储
- redis 是分布式缓存，是挡在mysql数据库前的一道屏障

#### 为什么要用Redis做缓存
1. **从高并发的角度说**：直接操作缓存能够承受的请求远远大于直接访问数据库的，所以我们可以考虑把数据库中的部分数据转移到缓存中去，这样用户的一部分请求会直接到缓存这里而不用经过数据库。
2. **从高性能上来说**:   用户第一次访问数据库中的某些数据。因为是从硬盘上读取的所以这个过程会比较慢。将该用户访问的数据存在缓存中，下一次再访问这些数据的时候就可以直接从缓存中获取了。操作缓存就是直接操作内存，所以速度相当快。如果数据库中的对应数据改变的之后，同步改变缓存中相应的数据。

#### redis主要功能
1. 内存存储和持久化（RDB+AOF）：redis支持异步将内存中的数据写到硬盘上，同时不影响继续服务✔
2. 高可用架构搭配保证（支持多个redis共用，防止一个瘫痪整个sql系统瘫痪）。即可以预防：缓存穿透、击穿、雪崩等问题
3. 支持分布式锁
4. 队列：Reids提供list和set操作，这使得Redis能作为一个很好的消息队列平台来使用。
5. 排行榜+点赞：在互联网应用中，有各种各样的排行榜，如电商网站的月度销量排行榜、社交APP的礼物排行榜、小程序的投票排行榜等等。Redis提供的set数据类型能够快速实现这些复杂的排行榜。

#### Redis 和 memcached的异同
- 都是内存数据库，memcached还可以存图片、视频。
- 存储数据类型：memcached的value只能是String，redis支持string/hash/list/set/sortedSet等数据结构。
- 虚拟内存：redis当内存用完时，可以把很久没用的value放到磁盘。
- redis是单线程，memcached是多线程的。
- Redis更可靠：memcached不支持持久化；redis可通过RDB快照和AOF日志持久化，所以支持灾难恢复，支持主从数据备份。
- 应用场景：redis除了可以做NoSQL数据库使用，还可以做消息队列、分布式锁等。

#### redis为什么这么快（端口号：6379）
1. **内存存储**：Redis是使用内存存储数据，避免了磁盘IO上的开销。数据存储在内存中。
2. **单线程实现**：Redis使用单个线程处理请求，避免了多个线程之间线程切换和锁资源争用的开销（redis6.0以前）
3. **非阻塞IO**：Redis使用多路复用IO技术，将epoll作为I/O多路复用技术的实现，再加上Redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费时间。
4. **优化的数据结构**：Redis有诸多可以直接应用的优化数据结构的实现，应用层可以直接使用原生的数据结构提升性能


#### Redis的常用场景
1. **缓存**：缓存现在几乎是所有中大型网站都在用的必杀技，合理的利用缓存不仅能够提升网站访问速度，还能大大降低数据库的压力Redis提供了键过期功能，也提供了灵活的键淘汰策略，所以，现在Redis用在缓存的场合比较多
2. **排行榜**：很多网站都有排行榜应用的，如京东的月度销量榜单、商品按时间的上新排行榜等。Redis提供的有序集合数据类构能实现各种复杂的排行榜应用。
3. **计数器**：什么是计数器，如电商网站商品的浏览量、视频网站视频的播放数等。为了保证数据实时效，每次浏览都得给+1，并发量高时如果每次都请求数据库操作无疑是种挑战和压力。Redis提供的incr命令来实现计数器功能，内存操作，性能非常好，非常适用于这些计数场景。
4. **分布式锁**：在很多互联网公司中都使用了分布式技术，分布式技术带来的技术挑战是对同一个资源的并发访问，如全局ID、减库存、秒杀等场景，并发量不大的场景可以使用数据库的悲观锁、乐观锁来实现，但在并发量高的场合中，利用数据库锁来控制资源的并发访问是不太理想的，大大影响了数据库的性能。可以利用Redis的setnx功能来编写分布式的锁，如果设置返回1说明获取锁成功，否则获取锁失败，实际应用中要考虑的细节要更多。
5. **社交网络**：点赞、踩、关注/被关注、共同好友等是社交网站的基本功能，社交网站的访问量通常来说比较大，而且传统的关系数据库类型不适合存储这种类型的数据，Redis提供的哈希、集合等数据结构能很方便的的实现这些功能。如在微博中的共同好友，通过Redis的set能够很方便得出。
6. **最新列表**：Redis列表结构，LPUSH可以在列表头部插入一个内容ID作为关键字，LTRIM可用来限制列表的数量，这样列表永远为N个ID，无需查询最新的列表，直接根据ID去到对应的内容页即可。

#### Redis十大常用数据结构 (前五个重点掌握)
（1）**String**
- string是redis最基本的类型，一个key对应一个value
其他的数据结构都是在String类型的基础上构建的
虽然Redis是用C语言写的，但是Redis并没有使用C语言的的String。而是自己构建了一种 简单动态字符串（SDS）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据（比如jpg图片或者序列化的对象）
- string类型是二进制安全的。
- 一个redis中字符串value最多可以是512M（小于1M扩容双倍，超过1M每次扩1M，最大512M）。
- 使用场景：一般常用在需要计数的场景，比如用户的访问次数、热点文章的点赞转发数量等等。

（2）**List**
- List结构是一个 单key多value的结构。
-  lpush + lpop = 栈、lpush + rpop = 队列、lpush + ltrim = 优先集合、lpush + brpop = 消息队列。
- 使用场景：发布与订阅或者说消息队列、慢查询。

（3）**hash**:
- hash结构保持了 k-v 模式不变，但v 又是一个新的键值对。类似于java中的Map<String, Map<Object,Object>。
- 使用场景：hash结构特别适合用于存储对象，故其常用于系统中对象数据的存储，如购物车中的物品信息等，每个物品使用一对 field-value，但只用一个键保存。  

（4） **set**:
- set结构是一个 单key多value结构，与list结构的区别是  无重复数据,是一个无序集合
- 当你需要存储一个列表数据，又不希望出现重复数据时，set 是一个很好的选择，并且 set 提供了判断某个成员是否在一个 set 集合内的重要接口，这个也是 list 所不能提供的。
- 使用场景：可以基于 set 轻易实现交集、并集、差集的操作。比如：你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。Redis 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。

（5）**sorted set/zset**
- 和set 相比，sorted set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。
- 使用场景：适用于需要对数据进行排序的场景。如根据商品价格进行排序等信息、或是排行榜系统等

（6）**Bitmap位图**
- 位图本质是数组，可以将其想象为一个仅有0 1构成的二进制bit数组，故其占用空间非常小。该数组由多个二进制位组成，每个二进制位都对应一个偏移量(索引)。它是用String类型作为底层数据结构实现的一种统计二值状态的数据类型。
- 使用场景：常用于存储大量的连续布尔值的数据，如：用户的签到等

（7）**Hyperloglog**
-  HyperLogLog 是一种用于统计基数的数据集合类型。它使用了一种 去重复统计功能 的基数估计算法。使用HyperLogLog，只需要花费12KB内存，就能计算 2的64次方=18446744073709551616 个不同元素的基数！！
-  HyperLogLog基数统计算法 是一个不精确的统计算法，标准误差为0.81%
- 使用场景：用于在输入元素的数量或体积非常大时，如统计网页的UV (即Unique Visitor,不重复访客，一个人访问某个网站多次，但是还是只计算为一次)

（8）** Geospatial**
- 主要用于存储地理位置信息，并对存储的信息进行操作。底层使用zset类型作为底层数据结构
- 使用场景：如朋友的定位、附近的人、打车距离计算等。

（9）**Stream**
- 主要用于消息队列，Stream流实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持ack确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠

（10）**bitfiled**
可以一次操作多个比特位域（多个连续的比特位）

### redis持久化
为了能够重用Redis数据，或者防止系统故障，我们需要将Redis中的数据写入到磁盘空间中，即持久化。Redis提供了两种不同的持久化方法可以将数据存储在磁盘中，一种叫快照RDB，另一种叫只追加文件AOF。

####  RDB
RDB实现类似照片记录效果的方式，就是把某一时刻的数据和状态以文件的形式写到磁盘上，也就是快照。这样一来即使故障宕机，快照文件也不会丢失，数据的可靠性也就得到了保证。 这个快照文件就称为RDB文件(dump.rdb)，其中，RDB就是Redis DataBase的缩写。
-  优势
   - 适合大规模的数据恢复
   - 按照业务定时备份
   - 对数据完整性和一致性要求不高
   - RDB文件在内存中的加载速度比AOF快得多
-  劣势
   - 在一定间隔时间做一次备份，如果redis意外down机，就会丢掉最近一次快照到down机时的数据
   - 内存数量的全量同步，如果数据量过大会导致IO严重影响服务器性能
   - RDB依赖于主进程的 fork，在更大的数据集中，这可能会导致服务器请求的瞬间延迟
   - fork的时候内存中的数据被克隆了一份，大致2倍的膨胀性，需要考虑

####  AOF
AOF以日志的形式来记录每个写操作，将Redis执行过的所有写指令记录下来(读操作不记录)，只许追加文件但不可以改写文件，Redis启动之初会读取该文件重新构建数据，换言之，Redis重启的话就根据日志文件的内容将写指令从前到后执行一次以完成数据的恢复工作。
   - AOF重写机制：AOF采用文件追加方式，文件会越来越大，为避免出现此种情况，新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。

- 优势
   - 更好的保护数据不丢失、性能高、可做紧急恢复
   
- 劣势
   - 相同数据集的数据而言aof文件要远大于rdb文件，恢复速度慢于rdb
   
   - aof运行效率要慢于rdb，每秒同步策略效率较好，不同步效率和rdb相同
   

#### 如何选择合适的持久化方式？
- 如果是数据不那么敏感，且可以从其他地方重新生成补回的，那么可以关闭持久化。
- 如果是数据比较重要，不想再从其他地方获取，且可以承受数分钟的数据丢失，比如缓存等，那么可以只使用RDB。
- 大多数情况推荐使用混合持久化的方式
   - 在同时开启rdb和aof持久化时，重启时只会加载aof文件，不会加载rbd文件。若aof文件不存在，才会加载rdb文件
   - 在通常情况下AOF文件保存的数据集要比RDB文件保存的数据集要完整, 但不推荐只使用AOF。 因为RDB更适合用于备份数据库（AOF不断变化不好备份），留着RDB作为备份。故推荐使用rdb+aof混合的方式，即使用RDB镜像作全量持久化，AOF作增量持久化


#### redis过期键的三个删除(淘汰)策略
**Redis过期键的删除策略**
Redis的过期删除策略就是:惰性删除和定期删除两种策略配合使用。
1. **惰性删除**
惰性删除不会去主动删除数据，设置该key过期时间后，我们不去管它，当需要该key时，我们在检查其是否过期，如果过期，我们就删掉它并返回null给客户端，反之则正常返回该key。
- **优点**: 对CPU友好，我们只会在使用该键时才会进行过期检查，对于很多用不到的key不用浪费时间进行过期检查。
- **缺点**: :对内存不友好，如果一个键已经过期，但是一直没有使用，那么该键就会一直存在内存中，如果数据库中有很多这种使用不到的过期键，这些键便永远不会被删除，内存永远不会释放。从而造成空间浪费 及 内存泄漏。

2. **定期删除**
Redis会周期性的随机测试一批设置了过期时间的key并进行处理。测试到的已过期的key将被删除。
- **优点**:可以通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响。另外定期删除，也能有效释放过期键占用的内存。
- **缺点**: 难以确定删除操作执行的时长和频率。如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好。如果执行的太少，那又和惰性删除一样了，过期键占用的内存不会及时得到释放。另外最重要的是，在获取某个键时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这个键的值，这是业务不能忍受的错误。

3. **定时删除**
在设置某个key的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。
- 优点:定时删除对内存是最友好的，能够保存内存的key一旦过期就能立即从内存中删除。
- 缺点:对CPU最不友好，在过期键比较多的时候，删除过期键会占用一部分CPU时间，对服务器的响应时间和吞吐量造成影响。


#### Redis内存淘汰策略（了解）
Redis是不断的删除一些过期数据，但是很多没有设置过期时间的数据也会越来越多，那么Redis内存不够用的时候是怎么处理的呢? 答案就是淘汰策略。此类的当Redis的内存超过最大允许的内存之后，Redis会触发内存淘汰策略，删除一些不常用的数据，以保证Redis服务器的正常运行。

* volatile-lru：利用LRU算法移除设置过过期时间的key
* allkeys-lru： 在键空间，移除最近最少使用的key（最常用）
* volatile-random:从已设置过期时间的数据集(server.db[j.expires) 中任意选择数据淘汰
* allkeys-random: 从数据集(server.db[i].dict) 中任意选择数据淘汰

Redisv4.0后增加以下两种:

* volatile-lfu:从已设置过期时间的数据集(server.db[i].expires)中挑选最不经常使用的数据淘汰(LFU(LeastFrequentlyUsed)算法，也就是最频繁被访问的数据将来最有可能被访问到)
* allkeys-lfu: 当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key。


### Redis事务
- Redis事务是一个单独的隔离操作，可以一次执行多个命令（一组命令的集合）。在一个事务中的所有命令都会序列化

####  redis事务 vs 传统的数据库事务
（1）redis命令执行是单线程架构，在执行完事务内所有指令前，不可能去同时执行其他客户端的请求(一致性)
（2）redis事务没有隔离级别的概念，所以就不会产生我们使用关系型数据库需要关注的脏读，幻读，重复读的问题。
（3）redis事务不能保证原子性，也就是不能保证所有的指令他同时成功或同时失败（没有执行到一半回滚的能力）(执行阶段某个命令出错，只有出错命令不被执行)
（Redis不支持直接回滚，但我们可以通过 Redis提供的一个命令来实现回滚）
（4）redis事务能保证一个事务内的命令依次执行，而不被其他命令插入(隔离性)

#### Redis为什么不支持事务回滚/不保证原子性
- Redis命令只会因为错误的语法而失败，或是命令用在了错误类型的键上面。。。这也就是说，从实用性的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发的过程中被发现，而不应该出现在生产环境中。。。即Redis主要认为失败都是使用者造成的所以就没有回滚操作。
- 因为不需要对回滚进行支持，所以 Redis的内部可以保持简单且快速。

### redis管道
- 管道(pipeline)可以一次性发送多条命令给服务端。服务端依次处理完完毕后，通过一条响应一次性将结果返回，管道通过减少客户端 与 redis的通信次数来实现降低往返延时时间。
- pipeline缓冲的指令只是会依次执行，不保证原子性，如果执行中指令发生异常，将会继续执行后续的指令
- 使用pipeline组装的命令个数不能太多，否则数据量过大 客户端 阻塞的时间可能过久，同时服务器也被迫回复一个队列答复，占用很多内存

#### Pipeline vs 原生批量命令
- 原生批量命令是原子性（如：mset，mget），pipeline是非原子性
- 原生批量命令一次只能执行一种命令，无法执行跨类型命令，pipeline支持批量执行不同命令
- 原生批命令是服务端实现，而pipeline需要服务端与客户端共同完成

#### pipeline vs 事务对比
- 事务具有原子性（不能保证），而管道不具有原子性
- 管道一次性将多条命令发送到服务器，事务是一条一条发的，事务只有在接收到exec命令后才会执行，管道不会（管道是批处理执行）
- 执行事务时会阻塞其他命令的执行，而执行管道中的命令时不会

### redis高可用
#### redis单副本
- 采用单个Redis节点部署架构，没有备用节点实时同步数据，不提供数据持久化和备份策略，适用于数据可靠性要求不高的纯缓存业务场景
- 优点:
   - 架构简单，部署方便;
   - 高性价比:缓存使用时无需备用节点(单实例可用性可以用supervisor或crontab保证) ，当然为了满足业务的高可用性，也可以牺牲一个备用节点，但同时刻只有一个实例对外提供服务;
   - 高性能。
- 缺点:
   - 不保证数据的可靠性;
   - 在缓存使用，进程重启后，数据丢失，即使有备用的节点解决高可用性，但是仍然不能解决缓存预热问题，因此不适用于数据可靠性要求高的业务 ;
   - 高性能受限于单核CPU的处理能力(Redis是单线程机制)，CPU为主要瓶颈，所以适合操作命令简单，排序、计算较少的场景。也可以考虑用Memcached替代

#### redis复制（多副本）
- Redis复制主要指的是 主从复制 功能，相较于单副本而言最大的特点就是主从实例间数据实时同步。即master以写为主，slave以读为主。当master数据变化时，自动将新的数据异步同步到其他slave数据库。主从复制能够解决如下问题，读写分离、down机恢复、数据备份、水平扩容支撑高并发
- redis复制的缺点
1. 复制延时，信号衰减
   - 由于所有的写操作都是先在Master上操作，然后同步更新到Slave上，所以从Master同步到Slave机器有一定的延迟。
   - 当系统很繁忙的时候，延迟问题会更加严重，Slave机器数量的增加也会使这个问题更加严重
2. master挂了
   - 默认情况下不会在slave节点自动重选一个master。 整个系统处于半瘫痪状

####  主从复制的原理解析
1. 首次全新连接master (全量复制)
   - slave启动成功连接到master后会发送一个sync命令。master节点收到sync命令后会在后台开始保存快照（即RDB持久化，主从复制会触发RDB），并将rdb快照文件和缓存的命令发送到所有slave。而slave服务在接收到快照文件后，一次完全同步（全量复制）将被自动执行，slave自身原有数据会被master数据覆盖清除
2. 增量复制
   - 在主库将数据同步给从库的过程中，主库不会阻塞，仍然可以正常接收请求。否则，redis的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的RDB文件中。 为了保证主从库的数据一敬性,主库会在内存中用专门的replication buffer,记录RDB文件生成收到的所有写操作。
   - 全量复制完成后, 主库会把全量复制执行过程中新收到的写命令。再发送给从库。具体的操作是，当主库完成RDB文件发送后，就会把此时replocation buffer中修改操作发送给从库，从库再执行这些操作。从而实现主从库同步
3. 保持通信
   - repl-ping-replica-period 10。。。。。master发出PING包的周期，默认是10秒
   - master将 新的所有收集到的修改命令（默认10s内的） 自动一次传给slave，完成同步
4. 重连续传
   - 当从机宕机时，主机 master 会检查backlog里面的offset、
   - master只会把offset后面的数据赋值给slave，类似断电续传

#### 主从架构数据丢失问题
1. 异步复制导致的数据丢失:
   - 因为master->slave的复制是异步的，所以可能有部分数据还没复制到slave，master就宕机了 ，此时这些部分数据就丢失了。
2. 脑裂导致的数据丢失
   - 某个master所在机器突然脱离了正常的网络，跟其他slave机器不能连接，但是实际上master还运行着，此时哨兵可能就会认为master宕机了，
   - 然后开启选举，将其他slave切换成了master。这个时候，集群里就会有两个master，也就是所谓的脑裂。此时虽然某个slave被切换成了master，但是可能client还没来得及切换到新的master,此时还继续写向旧master的数据可能也丢失了。当旧master再次恢复的时候，会被作为一个slave挂到新的master上去，自己的数据会清空，重新从新的master复制数据。
3. 优化主从架构数据丢失问题:
   - min-slaves-max-1ag 默认情况下是10。 上面的配置的意思是 数据复制和同步的延迟不能超过10秒。如果说一旦所有的slave，数据复制和同步的延迟都超过了10秒钟，那么这个时候，master就不会再接收任何请求了。通过减小min-slaves-max-1ag参数的值，这样就可以避免在发生故障时大量的数据丢失，一旦发现延迟超过了该值, 就不会往master中写入数据。
   - 此时可以将数据暂时写入本地缓存和磁盘中，在一段时间后重新写入master来保证数据不丢失; 也可以将数据写入kafka消息队列，隔一段时间去消费kafka中的数据。

#### redis哨兵
- redis哨兵介绍：主从模式下，当主服务器宕机后，需要手动把一台从服务器切换为主服务器，这就需要人工干预，费事费力，还会造成一段时间内服务不可用。这种方式并不推荐，实际生产中，我们优先考虑哨兵模式。这种模式下，master宕机，哨兵会自动选举master并将其他的slave指向新的master。

- 哨兵的四个功能
1. 主从监控：监控主从redis库 (包括master和slave) 运行是否正常
2. 消息通知：哨兵可以将故障转移的结果发送到客户端
3. 故障转移：如果master异常，则会进行主从切换，将其中一个slave作为新master
4. 配置中心：客户端通过连接哨兵来获得当前Redis服务的主节点地址

- 哨兵使用建议
1. 哨兵节点的数量应为多个，哨兵本身应该集群，保证高可用
2.  哨兵节点的数量应该是奇数个
3. 各个哨兵节点的配置应该一致
4. 如果哨兵节点部署在Docker等容器里，要注意端口的正确映射
5. 哨兵集群 + 主从复制，并不能保证数据零丢失（选出新master需要时间，所以引出集群的概念）

####  redis哨兵的运行流程以及选举原理
1. SDOWN主观下线: 即单个sentinel 自己主观上检测到的关于master的状态，从sentinel的角度来看，如果发送了PING心跳后，在一定时间内没有收到合法的回复，就达到了SDOWN的条件
2. ODOWN客观下线： ODOWN需要一定数量的sentinel（quorum），多个哨兵达成一致意见才能认为一个master客观上已经宕机
3. 当主节点被判断客观下线以后，各个哨兵节点会进行协商，选举出一个 领导者哨兵（哨兵代表） 节点。 并由该领导者节点进行故障迁移（Raft算法 选出领导者节点，基本思路就是先到先得~）
4. 领导者哨兵依次比较 所有slave的 priority/replication offset/run id， 谁的更大谁就是新的mater (如果priority相同再比较replication offset)
   - slave priority越低，优先级就越高
   - slave复制了越多的数据，offset越靠后， 优先级就越高
   - 如果一个slave跟master断开连接已经超过了down-after-milliseconds的10倍，那么slave就会认为其不适合被选举为master.
5. Sentinel leader会对新选举出来的新master执行slaveof no one操作，将其提升为master节点。Sentinel leader然后向其他slave发送命令，让剩余的slave成为新的matster的slave。若 原master重新上线，Sentinel leader会让原master降级为slave恢复正常工作

#### redis集群
- 若业务量过重，单个Master的复制集（大量的写操作命令集）将难以承担，因此我们需要让Master水平扩展。每个master只负责 整个操作命令集 的一部分（即外部指令传给某一个master），这就是Redis的集群， 当一个节点宕机，其后的slave立刻顶上，最终实现海量数据的高可用
- 集群的功能：
   - Redis集群支持多个Master，每个Master又可以挂载多个Slave，实现了海量数据的高可用
   - 由于Cluster自带Sentinel的故障转移机制，内置了高可用的支持，无需再去使用哨兵功能！
   - 客户端和Redis的节点连接，不再需要连接集群中所有节点，只需连接集群中的任意一个可用节点即可
   - 槽位slot负责分配到各个物理服务节点，由对应的集群来负责维护节点、插槽和数据之间的关系

#### 哈希槽分片
- 分片就是将你的数据拆分到多个 Redis 实例的过程
-  哈希槽实质就是一个数组，数组[0,2^14 -1]形成hash slot空间。
在数据和对应节点之间又加入了一层哈希槽（slot），用于管理数据和节点之间的关系。
- 槽位：redis集群设有 16384 个哈希槽（记着就行），集群的每个master负责一部分哈希槽。如当前集群有三个节点，每个节点负责一些槽位，如节点1负责0-5460，节点2负责5461-10922，节点3负责10923-16384 （分片）
- 接下来只需要通过确定的算法，决定当前命令将由哪些槽位负责（由哪些节点负责即可）（CRC算法： CRC16(key) % 16384）
   - ✔优点：哈希槽分片最大的好处是方便扩容和缩容，比如在上述例子中想要添加节点4，只需要将节点1 2 3 中的槽位匀给节点4即可，由于槽位的移动并不会停止服务，所以扩容和缩容并不会造成集群不可用的状态
   - ✔缺点：Redis集群不保证 强一致性，这意味着在特定的条件下，Redis集群可能会丢掉一些被系统收到的写入请求命令 （比如某节点在同步数据给其slave时宕机，其实slave上位时会有部分数据丢失）








### redis缓存异常
- 存在以下异常情况，（1）缓存与数据库的数据不一致（2）缓存雪崩（3）缓存击穿（4）缓存穿透

#### 缓存与数据库的数据不一致
-  一般我们在更新数据库数据时，需要同步redis中缓存的数据，所以存在两种方法：第一种方案：先执行update操作，再执行缓存清除。 第二种方案：先执行缓存清除，再执行update操作。这两种方案的弊端是当存在并发请求时，很容易出现以下问题：
   - 第一种方案：当请求1执行update操作后，还未来得及进行缓存清除，此时请求2查询到并使用了redis中的旧数据。
   - 第二种方案：当请求1执行清除缓存后，还未进行update操作，此时请求2进行查询到了旧数据并写入了redis。

- ✔mysql 和 redis 数据一致性是一个复杂的课题，通常是多种策略同时使用，例如：延迟双删、redis 过期淘汰、通过路由策略串行处理同类型数据、分布式锁等等。

#### （1）延时双删
- 延迟双删策略是分布式系统中数据库存储和缓存数据保持一致性的常用策略，但它不是强一致
- 工作流程：
1. 服务节点删除 redis 主库数据。（一删）
2. 服务节点修改 mysql 主库数据。
3. 服务节点使得当前业务处理 等待一段时间，等 redis 和 mysql 主从节点数据同步成功。
4. 服务节点从 redis 主库删除数据。（二删）
5. 当前或其它服务节点读取 redis 从库数据，发现 redis 从库没有数据，从 mysql 从库读取数据，并写入 redis 主库。
- 设置延迟时间，是因为 mysql 和 redis 主从节点数据同步不是实时的，所以需要等待一段时间，去增强它们的数据一致性。

#### （2）redis 过期淘汰
所以 redis 的定位是缓存热点数据，热点数据应该设置过期时间，当数据过期后，redis 会自动淘汰，这样当业务服务节点从 redis 查询已淘汰的数据时，查询不到数据，会重新从 mysql 数据库读取数据写入 redis。这也是加强 redis / mysql 数据一致性的相对简单有效的方法。

#### （3）路由策略串行处理同类型数据
很多时候，数据不一致是因为多个节点并行读写共享数据导致。如果某些特定业务只落在某个进程某个线程上独立 串行 处理，也能够在一定程度上增强 数据一致性。

#### 缓存雪崩
- 缓存雪崩是指缓存同一时间大面积的失效，导致大量的请求落到数据库上，造成数据库短时间内承受大量请求而崩掉。这就是缓存雪崩。

- 解决方案：
1. 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
2. 一般并发量不是特别多的时候，使用最多的解决方案是加锁排队。
3. 给每一个缓存数据增加相应的缓存标记，记录缓存的是否失效，如果缓存标记失效，则更新数据缓存。


#### 缓存击穿
- 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存雪崩是大规模的key失效，而缓存击穿是某个热点的key失效，

- 解决方案:
1. 设置热点数据永远不过期。永不过期实际包含两层意思:
   - 物理不过期，针对热点key不设置过期时间
   - 逻辑过期，把过期时间存在key对应的value里， 如果发现要过期了，通过一个后台的异步线程进行缓存的构建
2. 加互斥锁，互斥锁。比如某个key只允许一个线程查询数据和写缓存，其他线程等待。这种方式会阻塞其他的线程，此时系统的吞吐量会下降
3. 缓存预热。缓存预热就是系统上线后，将相关的缓存数据直接加载到缓存系统。这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题
   - 数据量不大的时候，工程启动的时候进行加载缓存动作；
   - 数据量大的时候，设置一个定时任务脚本，进行缓存的刷新；
   - 数据量太大的时候，优先保证热点数据进行提前加载到缓存。
4. 缓存降级。缓存降级是指缓存失效或缓存服务器挂掉的情况下，不去访问数据库，直接返回默认数据或访问服务的内存数据。降级一般是有损的操作，所以尽量减少降级对于业务的影响程度。在进行降级之前要对系统进行梳理，看看系统是不是可以丢卒保帅；从而梳理出哪些必须誓死保护，哪些可降级；比如可以参考日志级别设置预案：
   - 一般：比如有些服务偶尔因为网络抖动或者服务正在上线而超时，可以自动降级；
   - 警告：有些服务在一段时间内成功率有波动（如在95~100%之间），可以自动降级或人工降级，并发送告警；
   - 错误：比如可用率低于90%，或者数据库连接池被打爆了，或者访问量突然猛增到系统能承受的最大阀值，此时可以根据情况自动降级或者人工降级；
   - 严重错误：比如因为特殊原因数据错误了，此时需要紧急人工降级。


#### 缓存穿透
- 缓存穿透是指 缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。即 用户每次请求该数据都要去数据库中查询一遍。如果有恶意攻击者不断请求系统中不存在的数据，会导致短时间大量请求落在数据库上，造成数据库压力过大，甚至导致数据库承受不住而宕机崩溃。
- 解决方法
1. 接口层增加校验，如用户鉴权校验，id做基础校验，id<=0的直接拦截；
2. 将无效的key存放进Redis中:
   当出现Redis查不到数据，数据库也查不到数据的情况，我们就把这个key保存到Redis中，设置value="null"，并设置其过期时间极短，后面再出现查询这个key的请求的时候，直接返回null，就不需要再查询数据库了，样可以防止攻击用户反复用同一个id暴力攻击。但这种处理方式是有问题的，假如传进来的这个不存在的Key值每次都是随机的，那存进Redis也没有意义。
3. 使用布隆过滤器:
   - 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的 bitmap 中，一个一定不存在的数据会被这个 bitmap 拦截掉，从而避免了对底层存储系统的查询压力。（布隆过滤器判定某个key不存在布隆过滤器中，那么就一定不存在， 如果判定某个key存在，那么很大可能是存在，但也存在一定的误判率）。
   - 于是我们可以在缓存之前再加一个布隆过滤器，将数据库中的所有key都存储在布隆过滤器中，在查询Redis前先去布隆过滤器查询key是否存在



#### redis缓存异常的解决方案
1、**事前:**
- 均匀过期:设置不同的过期时间，让缓存失效的时间尽量均匀，避免相同的过期时间导致缓存雪崩，造成大量数据库的访问。如把每个Key的失效时间都加个随机值，setRedis (Key, value,time + Math. random()*10000），保证数据不会在同一时间大面积失效。
- 分级缓存:第一级缓存失效的基础上，访问二级缓存，每一级缓存的失效时间都不同。
- 热点数据缓存永远不过期。
- 保证Redis缓存的高可用，防止Redis宕机导致缓存雪崩的问题。可以使用主从+哨兵，Redis集群来避免Redis全盘崩溃的情况。

2、**事中:**

* 互斥锁
* 使用熔断机制，限流降级。当流量达到一定的阈值，直接返回”系统拥挤"之类的提示，防止过多的请求打在数据库上将数据库击垮，至少能保证一部分用户是可以正常使用，其他用户多刷新几次也能得到结果。

3、**事后:**
开启Redis持久化机制，尽快恢复缓存数据，一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。

### redis6.0
#### Redis为何使用单线程
核心意思就是，对于一个DB来说，CPU 通常不会是瓶颈，因为大多数请求不会是CPU密集型的，而是I/O密集型。具体到Redis的话，如果不考虑RDB/AOF等持久化方案，Redis是 完全的纯内存操作，执行速度是非常快的（能够达到8w~10w的QPS），因此这部分操作通常不会是性能瓶颈，Redis真正的性能瓶颈在于网络I/O，也就是客户端和服务端之间的网络传输延迟，因此Redis选择了单线程的I/O多路复用来实现它的核心网络模型。


#### Redis6.0为何引入多线程
对于更大的公司（所需求的QPS可能超过了10w），Reids的网络I/O瓶颈已经越来越明显了，Redis的单线程模式会导致系统消耗很多CPU时间在网络I/O上从而降低吞吐量。所以redis提供了多线程，注意，redis提供的多线程指的是IO的多线程，✔其内部命令还是单线程。



#### 介绍一下Redis的线程模型
**redis6.0** 之前Redis是基于reactor模式开发了网络事件处理器，这个处理器叫做文件事件处理器( file eventhandler)。由于这个文件事件处理器是单线程的，所以Redis才叫做单线程的模型。采用I0多路复用机制同时监听多个Socket，根据socket上的事件来选择对应的事件处理器来处理这个事件。

![image-20220525145534794](image\28.png)

文件事件处理器的结构包含了四个部分:

* 多个Socket。 Socket会产生AE_ _READABLE和AE_ WRITABLE事件:
  * 当socket变得可读时或者有新的可以应答的socket出现时，socket就会产生一个AE_ READABLE事件
  * 当socket变得可写时，socket就会产生一一个AE_ WRITABLE事件。
* I0多路复用程序
* 文件事件分派器
* 事件处理器。事件处理器包括:连接应答处理器、命令请求处理器、命令回复处理器，每个处理器对应不同的socket事件:
  * 如果是客户端要连接Redis，那么会为socket关联连接应答处理器
  * 如果是客户端要写数据到Redis(读、写请求命令)，那么会为socket关联命令请求处理器
  * 如果是客户端要从Redis读数据，那么会为socket关联命令回复处理器

多个socket会产生不同的事件，不同的事件对应着不同的操作，I0多路复用程序监听着这些Socket,当这些Socket产生了事件，I0多路复用程序会将这些事件放到一个队列中，通过这个队列，以有序、同步、每次一个事件的方式向文件时间分派器中传送。当事件处理器处理完一个事件后，I0多路复用程序才会继续向文件分派器传送下一个事件。

#### Redis多线程的实现机制
流程简述如下：
* 主线程负责接收建立连接请求，获取Socket放入全局等待读处理队列。
* 主线程处理完读事件之后，通过RR (Round Robin)将这些连接分配给这些I0线程。
* 主线程阻塞等待I0线程读取Socket完毕。
* 主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行。
* 主线程阻塞等待I0线程将数据回写Socket完毕。

#### Redis6.0开启多线程后，是否会有线程并发安全问题
从实现机制可以看出，Redis的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程顺序执行。所以我们不需要去考虑控制Key、Lua、事务，LPUSH/LPOP等等的并发及线程安全问题。

#### Redis6.0与Memcached多线程模型的对比
* 相同点:都采用了Master线程Worker线程的模型。
* 不同点:Memcached执行主逻辑也是在Worker线程里，模型更加简单，实现了真正的线程隔离，符合我们对线程隔离的常规理解。而Redis把处理逻辑交还给Master线程，虽然一定程度 上增加了模型复杂度，但也解决了线程并发安全等问题。

#### 什么是分布式锁?为什么用分布式锁?
锁在程序中的作用就是同步工具，保证共享资源在同一时刻只能被一个线程访问，Java中的锁我们都很熟悉了，像synchronized 、Lock都是我们经常使用的，但是Java的锁只能保证单机的时候有效，分布式集群环境就无能为力了，这个时候我们就需要用到分布式锁。分布式锁，顾名思义，就是分布式项目开发中用到的锁，可以用来控制分布式系统之间同步访问共享资源。
**思路是:**在整个系统提供一个全局、唯一的获取锁的"东西”，然后每个系统在需要加锁时，都去问这个“东西”拿到一把锁，这样不同的系统拿到的就可以认为是同一把锁。至于这个”东西”，可以是Redis、Zookeeper，也可以是数据库。
一般来说，分布式锁需要满足的特性有这么几点:

* 互斥性:在任何时刻，对于同一条数据，只有一台应用可以获取到分布式锁;
* 高可用性:在分布式场景下，一小部分服务器宕机不影响正常使用，这种情况就需要将提供分布式锁的服务以集群的方式部署;
* 防止锁超时:如果客户端没有主动释放锁，服务器会在一段时间之后自动释放锁，防止客户端宕机或者网络不可达时产生死锁;
* 独占性:加锁解锁必须由同一台服务器进行，也就是锁的持有者才可以释放锁，不能出现你加的锁, 别人给你解锁了。

#### 分布式锁的三个核心要素
**加锁**
当一个线程执行setnx返回1，说明key原本不存在，该线程成功得到了锁;
当一个线程执行setnX返回0，说明键已经存在，该线程抢锁失败；

~~~java
setx key chen
~~~

**解锁**
有加锁就得有解锁。当得到的锁的线程执行完任务，需要释放锁，以便其他线程可以进入。释放锁的最简单方式就是执行del指令。

释放锁之后，其他线程就可以继续执行setnx命令来获得锁。

~~~java
del key
~~~

**锁超时**
锁超时知道的是:如果一个得到锁的线程在执行任务的过程中挂掉，来不及显式地释放锁，这块资源将会永远被锁住，别的线程别想进来。所以，setnx的key必须设置一个超时时间，以保证即使没有被显示释放，这把锁也要在一段时间后自动释放。setnx不支持超时参数，所以需要额外指令

~~~java
expire key 30
~~~

#### 上述分布式锁存在的问题
**SETNX和EXPIRE非原子性**
假设一个场景中，某一个线程刚执行setnx，成功得到了锁。此时setnx刚执行成功，还未来得及执行expire命令，节点就挂掉了。此时这把锁就没有设置过期时间，别的线程就再也无法获得该锁。
解决措施:
由于setnx指令本身是不支持传入超时时间的，而在Redis2.6.12版本.上为set指令增加了可选参数,用法如下:

~~~java
SET key value [EX seconds] [PX milliseconds] [NX |Xx]
~~~

* EX second:设置键的过期时间为second秒;
* PX millisecond:设置键的过期时间为millisecond毫秒; 
* NX: 只在键不存在时，才对键进行设置操作;
* XX:只在键已经存在时，才对键进行设置操作;
* SET操作完成时，返回OK，否则返回nil。

**锁误解除**
如果线程A成功获取到了锁，并且设置了过期时间30秒，但线程A执行时间超过了30秒，锁过期自动释放，此时线程B获取到了锁;随后A执行完成，线程A使用DEL命令来释放锁，但此时线程B加的锁还没有执行完成，线程A实际释放的线程B加的锁。

* **解决办法:**
  在del释放锁之前加一个判断，验证当前的锁是不是自己加的锁。
  具体在加锁的时候把当前线程的id当做value，可生成一个UUID标识当前线程，在删除之前验证key对应的value是不是自己线程的id。还可以使用lua脚本做验证标识和解锁操作。

**超时解锁导致并发**
如果线程A成功获取锁并设置过期时间30秒，但线程A执行时间超过了30秒，锁过期自动释放，此时线程B获取到了锁，线程A和线程B并发执行。A、B两个线程发生并发显然是不被允许的，一般有两种方式解决该问题:

* 将过期时间设置足够长，确保代码逻辑在锁释放之前能够执行完成。
* 为获取锁的线程增加守护线程，为将要过期但未释放的锁增加有效时间。

**不可重复入**

当线程在持有锁的情况下再次请求加锁，如果一个锁支持一个线程多次加锁，那么这个锁就是可重入的。如果一个不可重入锁被再次加锁，由于该锁已经被持有，再次加锁会失败。Redis可通过对锁进行重入计数，加锁时加1，解锁时减1，当计数归0时释放锁。

#### RedLock
Redlock是一种算法，Redlock 也就是Redis Distributed Lock，可用实现多节点Redis的分布式锁。是一种算法，Redlock也就是Redis分布式锁，可用实现多节点Redis的分布式锁。RedLock官方推荐，Redisson完成了对Redlock算法封装。此种方式具有以下特性:

* 互斥访问:即永远只有一个client能拿到锁
* 避免死锁:最终client都可能拿到锁，不会出现死锁的情况，即使锁定资源的服务崩溃或者分区，仍然能释放锁。
* 容错性:只要大部分Redis节点存活(一半以上)，就可以正常提供服务
  

#### 如果现在有个读超高并发的系统，用redis来抗住大部分读请求，你怎么设计
如果是读高并发的话，先看读并发的数量级是多少，因为Redis单机的读QPS在万级，每秒几万没问题，使用一主多从+哨兵集群的缓存架构来承载每秒10W+的读并发，主从复制，读写分离。使用哨兵集群主要是提高缓存架构的可用性，解决单点故障问题。主库负责写，多个从库负责读，支持水平扩容，根据读请求的QPS来决定加多少个Redis从实例。如果读并发继续增加的话，只需要增加Redis从实例就行了。如果需要缓存1T+的数据，选择Redis cluster模式，每个主节点存一部分数据，假设一个master存32G，那只需要n*32G>=1T, n个这样的master节点就可以支持1T+的海量数据的存储了。





